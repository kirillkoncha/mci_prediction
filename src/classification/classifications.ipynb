{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00bf877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7705db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99e64ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/kirillkonca/Documents/dementia_prediction/data_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "becc6cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>speech</th>\n",
       "      <th>annotation</th>\n",
       "      <th>speaking time (s)</th>\n",
       "      <th>on</th>\n",
       "      <th>co</th>\n",
       "      <th>mean_sent_embs</th>\n",
       "      <th>mlu</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>...</th>\n",
       "      <th>pid</th>\n",
       "      <th>pid_efficiency</th>\n",
       "      <th>maas</th>\n",
       "      <th>frazier_score</th>\n",
       "      <th>words_per_clause</th>\n",
       "      <th>mmse</th>\n",
       "      <th>short_pause</th>\n",
       "      <th>mid_pause</th>\n",
       "      <th>long_pause</th>\n",
       "      <th>mean_surprisal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138-1</td>\n",
       "      <td>Control</td>\n",
       "      <td>there's a cookie jar on the shelf . and the li...</td>\n",
       "      <td># sent_id = 1\\n# text = there's a cookie jar o...</td>\n",
       "      <td>46.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.802693</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>0.589552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123539</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.025319</td>\n",
       "      <td>0.727537</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.843843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631-0</td>\n",
       "      <td>Control</td>\n",
       "      <td>the kids are in the cookies . the stool is fal...</td>\n",
       "      <td># sent_id = 1\\n# text = the kids are in the co...</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.853938</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059091</td>\n",
       "      <td>0.233236</td>\n",
       "      <td>0.024072</td>\n",
       "      <td>0.868304</td>\n",
       "      <td>4.461538</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.742492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121-0</td>\n",
       "      <td>Control</td>\n",
       "      <td>the boy is taking a cookie out of the cookie j...</td>\n",
       "      <td># sent_id = 1\\n# text = the boy is taking a co...</td>\n",
       "      <td>128.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.801815</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218210</td>\n",
       "      <td>0.554471</td>\n",
       "      <td>0.026686</td>\n",
       "      <td>0.719372</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.826125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142-3</td>\n",
       "      <td>Control</td>\n",
       "      <td>the water's running over on the floor . the st...</td>\n",
       "      <td># sent_id = 1\\n# text = the water's running ov...</td>\n",
       "      <td>16.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.838216</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280952</td>\n",
       "      <td>0.653983</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>1.004314</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.550135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267-2</td>\n",
       "      <td>Control</td>\n",
       "      <td>mother is drying the dishes and looking out th...</td>\n",
       "      <td># sent_id = 1\\n# text = mother is drying the d...</td>\n",
       "      <td>39.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795138</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304233</td>\n",
       "      <td>0.956938</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.910656</td>\n",
       "      <td>6.529412</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.018967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id diagnosis                                             speech  \\\n",
       "0  138-1   Control  there's a cookie jar on the shelf . and the li...   \n",
       "1  631-0   Control  the kids are in the cookies . the stool is fal...   \n",
       "2  121-0   Control  the boy is taking a cookie out of the cookie j...   \n",
       "3  142-3   Control  the water's running over on the floor . the st...   \n",
       "4  267-2   Control  mother is drying the dishes and looking out th...   \n",
       "\n",
       "                                          annotation  speaking time (s)   on  \\\n",
       "0  # sent_id = 1\\n# text = there's a cookie jar o...              46.20  0.0   \n",
       "1  # sent_id = 1\\n# text = the kids are in the co...              17.15  0.0   \n",
       "2  # sent_id = 1\\n# text = the boy is taking a co...             128.05  0.0   \n",
       "3  # sent_id = 1\\n# text = the water's running ov...              16.82  0.0   \n",
       "4  # sent_id = 1\\n# text = mother is drying the d...              39.71  0.0   \n",
       "\n",
       "         co  mean_sent_embs        mlu  stop_words  ...       pid  \\\n",
       "0  0.105263        0.802693   9.571429    0.589552  ...  0.123539   \n",
       "1  0.000000        0.853938   7.250000    0.534483  ...  0.059091   \n",
       "2  0.153846        0.801815  11.666667    0.567857  ...  0.218210   \n",
       "3  0.285714        0.838216   7.000000    0.500000  ...  0.280952   \n",
       "4  0.000000        0.795138  10.090909    0.549550  ...  0.304233   \n",
       "\n",
       "   pid_efficiency      maas  frazier_score  words_per_clause  mmse  \\\n",
       "0        0.324675  0.025319       0.727537          6.090909  28.0   \n",
       "1        0.233236  0.024072       0.868304          4.461538  29.0   \n",
       "2        0.554471  0.026686       0.719372          6.666667  30.0   \n",
       "3        0.653983  0.019465       1.004314          6.000000  30.0   \n",
       "4        0.956938  0.023439       0.910656          6.529412  30.0   \n",
       "\n",
       "   short_pause  mid_pause  long_pause  mean_surprisal  \n",
       "0            0          0           1        4.843843  \n",
       "1            0          0           0        5.742492  \n",
       "2            0          1           0        4.826125  \n",
       "3            0          0           0        6.550135  \n",
       "4            2          0           0        5.018967  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33c2c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average=\"macro\", zero_division=0)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = list(stop_words)\n",
    "scoring = {\n",
    "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'recall_macro': make_scorer(recall_score, average='macro', zero_division=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6648bd",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62a2b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0ca56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MCI vs. AD\": df[df['diagnosis'].isin(['MCI', 'AD'])],\n",
    "    \"MCI vs. Control\": df[df['diagnosis'].isin(['MCI', 'Control'])],\n",
    "    \"AD vs. Control\": df[df['diagnosis'].isin(['AD', 'Control'])],\n",
    "    \"MCI vs. AD vs. Control\": df\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"SVM\": SVC(random_state=42, class_weight='balanced'),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d953b9",
   "metadata": {},
   "source": [
    "## MMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac4d65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.8200 ± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8200 ± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8200 ± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5714 ± 0.1125\n",
      "Precision-Macro: 0.6067\n",
      "Recall-Macro: 0.6140\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6169 ± 0.1504\n",
      "Precision-Macro: 0.6658\n",
      "Recall-Macro: 0.6407\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6109 ± 0.1687\n",
      "Precision-Macro: 0.6256\n",
      "Recall-Macro: 0.6503\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9575 ± 0.0327\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9640\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9550 ± 0.0321\n",
      "Precision-Macro: 0.9552\n",
      "Recall-Macro: 0.9603\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9571 ± 0.0401\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.6755 ± 0.0696\n",
      "Precision-Macro: 0.7061\n",
      "Recall-Macro: 0.7279\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6951 ± 0.0567\n",
      "Precision-Macro: 0.7134\n",
      "Recall-Macro: 0.7616\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6951 ± 0.0567\n",
      "Precision-Macro: 0.7134\n",
      "Recall-Macro: 0.7616\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df[['mmse']].values\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        cv_results = cross_validate(model, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"MMSE\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d0a23",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e91f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6586 ± 0.1372\n",
      "Precision-Macro: 0.6785\n",
      "Recall-Macro: 0.6610\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.4796 ± 0.0915\n",
      "Precision-Macro: 0.4756\n",
      "Recall-Macro: 0.4958\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.8078 ± 0.0699\n",
      "Precision-Macro: 0.8111\n",
      "Recall-Macro: 0.8112\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8082 ± 0.0576\n",
      "Precision-Macro: 0.8120\n",
      "Recall-Macro: 0.8151\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.7814 ± 0.0580\n",
      "Precision-Macro: 0.7875\n",
      "Recall-Macro: 0.7906\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5029 ± 0.0276\n",
      "Precision-Macro: 0.4910\n",
      "Recall-Macro: 0.5239\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5140 ± 0.0206\n",
      "Precision-Macro: 0.4968\n",
      "Recall-Macro: 0.5381\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5079 ± 0.0340\n",
      "Precision-Macro: 0.5004\n",
      "Recall-Macro: 0.5217\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df['speech']\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words)),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"TF-IDF + MMSE\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58a146",
   "metadata": {},
   "source": [
    "## TF-IDF + MMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2cdf1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8170 ± 0.0721\n",
      "Precision-Macro: 0.7851\n",
      "Recall-Macro: 0.8916\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8357 ± 0.0816\n",
      "Precision-Macro: 0.7966\n",
      "Recall-Macro: 0.9386\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6503 ± 0.1624\n",
      "Precision-Macro: 0.7113\n",
      "Recall-Macro: 0.6416\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6218 ± 0.1890\n",
      "Precision-Macro: 0.6314\n",
      "Recall-Macro: 0.6372\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9257 ± 0.0444\n",
      "Precision-Macro: 0.9297\n",
      "Recall-Macro: 0.9282\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9622 ± 0.0315\n",
      "Precision-Macro: 0.9610\n",
      "Recall-Macro: 0.9682\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9551 ± 0.0339\n",
      "Precision-Macro: 0.9540\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5972 ± 0.0315\n",
      "Precision-Macro: 0.5778\n",
      "Recall-Macro: 0.6240\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6640 ± 0.0767\n",
      "Precision-Macro: 0.6686\n",
      "Recall-Macro: 0.6736\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6872 ± 0.0876\n",
      "Precision-Macro: 0.7010\n",
      "Recall-Macro: 0.6910\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df[['speech', 'mmse']]\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    # Define column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "            ('mmse', StandardScaler(), ['mmse'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"TF-IDF + MMSE\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ceaa035",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "129f4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.571365</td>\n",
       "      <td>0.606726</td>\n",
       "      <td>0.613954</td>\n",
       "      <td>0.112546</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.616925</td>\n",
       "      <td>0.665836</td>\n",
       "      <td>0.640670</td>\n",
       "      <td>0.150424</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Task                Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "0       MCI vs. AD        Random Forest       0.820021              0.778155   \n",
       "1       MCI vs. AD                  SVM       0.820021              0.778155   \n",
       "2       MCI vs. AD  Logistic Regression       0.820021              0.778155   \n",
       "3  MCI vs. Control        Random Forest       0.571365              0.606726   \n",
       "4  MCI vs. Control                  SVM       0.616925              0.665836   \n",
       "\n",
       "   Mean Recall Macro    Std F1  Type  \n",
       "0           0.931896  0.074311  MMSE  \n",
       "1           0.931896  0.074311  MMSE  \n",
       "2           0.931896  0.074311  MMSE  \n",
       "3           0.613954  0.112546  MMSE  \n",
       "4           0.640670  0.150424  MMSE  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97318c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.962242</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.968169</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.835719</td>\n",
       "      <td>0.796607</td>\n",
       "      <td>0.938616</td>\n",
       "      <td>0.081554</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.695081</td>\n",
       "      <td>0.713441</td>\n",
       "      <td>0.761550</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.650258</td>\n",
       "      <td>0.711317</td>\n",
       "      <td>0.641573</td>\n",
       "      <td>0.162386</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Task                Model  Mean F1 Macro  \\\n",
       "31          AD vs. Control                  SVM       0.962242   \n",
       "26              MCI vs. AD  Logistic Regression       0.835719   \n",
       "10  MCI vs. AD vs. Control                  SVM       0.695081   \n",
       "28         MCI vs. Control                  SVM       0.650258   \n",
       "\n",
       "    Mean Precision Macro  Mean Recall Macro    Std F1           Type  \n",
       "31              0.961029           0.968169  0.031528  TF-IDF + MMSE  \n",
       "26              0.796607           0.938616  0.081554  TF-IDF + MMSE  \n",
       "10              0.713441           0.761550  0.056706           MMSE  \n",
       "28              0.711317           0.641573  0.162386  TF-IDF + MMSE  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_results.loc[baselines_results.groupby('Task')['Mean F1 Macro'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ae63c",
   "metadata": {},
   "source": [
    "# All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de4dfbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4855 ± 0.0475\n",
      "Precision-Macro: 0.4916\n",
      "Recall-Macro: 0.5100\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6089 ± 0.1301\n",
      "Precision-Macro: 0.6064\n",
      "Recall-Macro: 0.6609\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5714 ± 0.1224\n",
      "Precision-Macro: 0.5769\n",
      "Recall-Macro: 0.6327\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5072 ± 0.1652\n",
      "Precision-Macro: 0.4749\n",
      "Recall-Macro: 0.5475\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5535 ± 0.1232\n",
      "Precision-Macro: 0.5554\n",
      "Recall-Macro: 0.5913\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5651 ± 0.1167\n",
      "Precision-Macro: 0.5787\n",
      "Recall-Macro: 0.6356\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.7306 ± 0.0842\n",
      "Precision-Macro: 0.7439\n",
      "Recall-Macro: 0.7344\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.7665 ± 0.0683\n",
      "Precision-Macro: 0.7707\n",
      "Recall-Macro: 0.7756\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.7577 ± 0.0702\n",
      "Precision-Macro: 0.7605\n",
      "Recall-Macro: 0.7668\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4772 ± 0.0345\n",
      "Precision-Macro: 0.4649\n",
      "Recall-Macro: 0.4994\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5086 ± 0.0924\n",
      "Precision-Macro: 0.5254\n",
      "Recall-Macro: 0.5078\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5086 ± 0.0724\n",
      "Precision-Macro: 0.5359\n",
      "Recall-Macro: 0.5352\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    features_columns = task_df.select_dtypes(include=[np.number]).drop(columns=['speaking time (s)']).columns.tolist()\n",
    "    features_columns.remove('mmse')\n",
    "    X = task_df[features_columns]\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"All Features\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3acbc",
   "metadata": {},
   "source": [
    "# TF-IDF + All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50821151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.7708 ± 0.1157\n",
      "Precision-Macro: 0.7653\n",
      "Recall-Macro: 0.8059\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8218 ± 0.1078\n",
      "Precision-Macro: 0.8095\n",
      "Recall-Macro: 0.8735\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6071 ± 0.1220\n",
      "Precision-Macro: 0.6242\n",
      "Recall-Macro: 0.6531\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5945 ± 0.1063\n",
      "Precision-Macro: 0.6008\n",
      "Recall-Macro: 0.6348\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9262 ± 0.0351\n",
      "Precision-Macro: 0.9264\n",
      "Recall-Macro: 0.9282\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9256 ± 0.0449\n",
      "Precision-Macro: 0.9248\n",
      "Recall-Macro: 0.9310\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9449 ± 0.0393\n",
      "Precision-Macro: 0.9440\n",
      "Recall-Macro: 0.9499\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5971 ± 0.0223\n",
      "Precision-Macro: 0.5773\n",
      "Recall-Macro: 0.6215\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6393 ± 0.0956\n",
      "Precision-Macro: 0.6485\n",
      "Recall-Macro: 0.6430\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6993 ± 0.0846\n",
      "Precision-Macro: 0.6949\n",
      "Recall-Macro: 0.7244\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    features_columns = task_df.select_dtypes(include=[np.number]).drop(columns=['speaking time (s)']).columns.tolist()\n",
    "    X = task_df[['speech'] + features_columns]\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    # Define column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "            ('num', StandardScaler(), features_columns)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"All Features\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c4097",
   "metadata": {},
   "source": [
    "# Linear Feature Addition to TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1657f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features.remove(\"speaking time (s)\")\n",
    "numerical_features.remove(\"mmse\")  # mmse will be added manually at the start\n",
    "numerical_features.insert(0, \"mmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4670501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: on, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: co, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.4679\n",
      "\n",
      "Final Selected Features: [], Final F1-Macro: 0.4679\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.8170\n",
      "✅ Added Feature: on, New F1-Macro: 0.8250\n",
      "❌ Skipped Feature: co, F1-Macro: 0.8256\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.8215\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.8104\n",
      "✅ Added Feature: stop_words, New F1-Macro: 0.8302\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.7993\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.7725\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.7791\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.8159\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.7990\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.8140\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.7882\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.8322\n",
      "✅ Added Feature: frazier_score, New F1-Macro: 0.8434\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.8315\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.8237\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.8222\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7798\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.8282\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'stop_words', 'frazier_score'], Final F1-Macro: 0.8434\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8434 ± 0.0864\n",
      "Precision-Macro: 0.8095\n",
      "Recall-Macro: 0.9201\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.6586\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.8357\n",
      "❌ Skipped Feature: on, F1-Macro: 0.8293\n",
      "❌ Skipped Feature: co, F1-Macro: 0.8291\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.8244\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.8254\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.8274\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.8163\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.8208\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.8282\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.8210\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.8293\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.8293\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.8357\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.8376\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.8144\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.8357\n",
      "✅ Added Feature: short_pause, New F1-Macro: 0.8438\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.8364\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.8438\n",
      "✅ Added Feature: mean_surprisal, New F1-Macro: 0.8535\n",
      "\n",
      "Final Selected Features: ['mmse', 'short_pause', 'mean_surprisal'], Final F1-Macro: 0.8535\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8535 ± 0.0808\n",
      "Precision-Macro: 0.8183\n",
      "Recall-Macro: 0.9370\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5085\n",
      "\n",
      "Final Selected Features: [], Final F1-Macro: 0.5085\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.6503\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6364\n",
      "❌ Skipped Feature: co, F1-Macro: 0.6533\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6259\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6024\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.6498\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6021\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.6111\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.6023\n",
      "✅ Added Feature: sid, New F1-Macro: 0.6555\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.6359\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6222\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6069\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.6258\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6176\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6287\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.6264\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5917\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.6299\n",
      "✅ Added Feature: mean_surprisal, New F1-Macro: 0.6857\n",
      "\n",
      "Final Selected Features: ['mmse', 'sid', 'mean_surprisal'], Final F1-Macro: 0.6857\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6857 ± 0.1956\n",
      "Precision-Macro: 0.7110\n",
      "Recall-Macro: 0.6739\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4796\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.6218\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6174\n",
      "✅ Added Feature: co, New F1-Macro: 0.6470\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6456\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6468\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.6337\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6469\n",
      "✅ Added Feature: verbs_with_inflections, New F1-Macro: 0.6634\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.6624\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.6411\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.6391\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6540\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6520\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.6587\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6466\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6473\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.6585\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.6554\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.6434\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.6454\n",
      "\n",
      "Final Selected Features: ['mmse', 'co', 'verbs_with_inflections'], Final F1-Macro: 0.6634\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6634 ± 0.1823\n",
      "Precision-Macro: 0.6618\n",
      "Recall-Macro: 0.6969\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8078\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.9257\n",
      "✅ Added Feature: on, New F1-Macro: 0.9306\n",
      "❌ Skipped Feature: co, F1-Macro: 0.9138\n",
      "✅ Added Feature: mean_sent_embs, New F1-Macro: 0.9357\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.9331\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.9257\n",
      "✅ Added Feature: tree_depth, New F1-Macro: 0.9428\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.9209\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.9281\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.9259\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.9378\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.9330\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.9380\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.9331\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.9309\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.9256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipped Feature: short_pause, F1-Macro: 0.9307\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.9253\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.9186\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.9283\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'mean_sent_embs', 'tree_depth'], Final F1-Macro: 0.9428\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9428 ± 0.0474\n",
      "Precision-Macro: 0.9428\n",
      "Recall-Macro: 0.9457\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8082\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.9622\n",
      "❌ Skipped Feature: on, F1-Macro: 0.9573\n",
      "❌ Skipped Feature: co, F1-Macro: 0.9622\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.9574\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.9623\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.9598\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.9623\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.9598\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.9574\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.9598\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.9550\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.9598\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.9599\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.9475\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.9573\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.9549\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.9526\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.9576\n",
      "\n",
      "Final Selected Features: ['mmse'], Final F1-Macro: 0.9622\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9622 ± 0.0315\n",
      "Precision-Macro: 0.9610\n",
      "Recall-Macro: 0.9682\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.7814\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.9551\n",
      "❌ Skipped Feature: on, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: co, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.9575\n",
      "✅ Added Feature: verbs_with_inflections, New F1-Macro: 0.9599\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.9573\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.9598\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.9477\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.9599\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.9574\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.9573\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.9598\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.9550\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.9574\n",
      "\n",
      "Final Selected Features: ['mmse', 'verbs_with_inflections'], Final F1-Macro: 0.9599\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9599 ± 0.0331\n",
      "Precision-Macro: 0.9581\n",
      "Recall-Macro: 0.9660\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5029\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.5972\n",
      "✅ Added Feature: on, New F1-Macro: 0.6026\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5920\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6037\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5989\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5989\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5956\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.6013\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5992\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5971\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5975\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5976\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5990\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5917\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5994\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6022\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5990\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5993\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5959\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5926\n",
      "\n",
      "Final Selected Features: ['mmse', 'on'], Final F1-Macro: 0.6026\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6026 ± 0.0330\n",
      "Precision-Macro: 0.5825\n",
      "Recall-Macro: 0.6289\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5140\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.6640\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6444\n",
      "✅ Added Feature: co, New F1-Macro: 0.7130\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.7020\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6349\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.7065\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6360\n",
      "✅ Added Feature: verbs_with_inflections, New F1-Macro: 0.7187\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.6810\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.6618\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.7015\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6795\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.7019\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.7051\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6895\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.7182\n",
      "✅ Added Feature: short_pause, New F1-Macro: 0.7409\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.7059\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7229\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.7219\n",
      "\n",
      "Final Selected Features: ['mmse', 'co', 'verbs_with_inflections', 'short_pause'], Final F1-Macro: 0.7409\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.7409 ± 0.0798\n",
      "Precision-Macro: 0.7518\n",
      "Recall-Macro: 0.7735\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5079\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.6872\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6769\n",
      "✅ Added Feature: co, New F1-Macro: 0.6945\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6844\n",
      "✅ Added Feature: mlu, New F1-Macro: 0.6982\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.6970\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6816\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.6829\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.6834\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.6899\n",
      "✅ Added Feature: sid_efficiency, New F1-Macro: 0.7054\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6733\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6940\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.7061\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6884\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6817\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.7021\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.6962\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7033\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.6962\n",
      "\n",
      "Final Selected Features: ['mmse', 'co', 'mlu', 'sid_efficiency'], Final F1-Macro: 0.7054\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.7054 ± 0.0737\n",
      "Precision-Macro: 0.7113\n",
      "Recall-Macro: 0.7256\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        X_text = task_df[['speech']]  # Start with text only\n",
    "        y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "        # Define TF-IDF for baseline\n",
    "        tfidf = TfidfVectorizer(ngram_range=(1, 1), max_features=5000, stop_words=stop_words)\n",
    "\n",
    "        baseline_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech')\n",
    "        ])\n",
    "\n",
    "        baseline_pipeline = Pipeline([\n",
    "            ('preprocessor', baseline_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        # Baseline: TF-IDF only\n",
    "        baseline_score = cross_val_score(baseline_pipeline, X_text, y, cv=kf, scoring=f1_scorer).mean()\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Baseline (TF-IDF only) F1-Macro: {baseline_score:.4f}\")\n",
    "\n",
    "        # Feature selection loop\n",
    "        best_score = baseline_score\n",
    "        selected_features = []\n",
    "\n",
    "        for feature in numerical_features:\n",
    "\n",
    "            current_features = selected_features + [feature]\n",
    "\n",
    "            preprocessor = ColumnTransformer([\n",
    "                ('tfidf', tfidf, 'speech'),\n",
    "                ('num', StandardScaler(), current_features)\n",
    "            ])\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "\n",
    "            X_all = task_df[['speech'] + current_features]\n",
    "            new_score = cross_val_score(pipeline, X_all, y, cv=kf, scoring=f1_scorer).mean()\n",
    "\n",
    "            if new_score - best_score >= best_score * 0.01:\n",
    "                best_score = new_score\n",
    "                selected_features.append(feature)\n",
    "                print(f\"✅ Added Feature: {feature}, New F1-Macro: {new_score:.4f}\")\n",
    "            else:\n",
    "                print(f\"❌ Skipped Feature: {feature}, F1-Macro: {new_score:.4f}\")\n",
    "\n",
    "        print(f\"\\nFinal Selected Features: {selected_features}, Final F1-Macro: {best_score:.4f}\")\n",
    "\n",
    "        # Final evaluation with all selected features\n",
    "        final_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech'),\n",
    "            ('num', StandardScaler(), selected_features)\n",
    "        ]) if selected_features else ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech')\n",
    "        ])\n",
    "\n",
    "        final_pipeline = Pipeline([\n",
    "            ('preprocessor', final_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        X_final = task_df[['speech'] + selected_features] if selected_features else task_df[['speech']]\n",
    "\n",
    "        final_scores = cross_validate(final_pipeline, X_final, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"\\n🔎 Final Evaluation with Selected Features:\")\n",
    "        print(f\"F1-Macro: {final_scores['test_f1_macro'].mean():.4f} ± {final_scores['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {final_scores['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {final_scores['test_recall_macro'].mean():.4f}\")\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": final_scores['test_f1_macro'].mean(),\n",
    "            \"Std F1\": final_scores['test_f1_macro'].std(),\n",
    "            \"Mean Precision Macro\": final_scores['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": final_scores['test_recall_macro'].mean(),\n",
    "            \"Type\": \"+\".join([\"TF-IDF\"] + selected_features) if selected_features else \"TF-IDF only\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e871a",
   "metadata": {},
   "source": [
    "# Linear Feature Deletion from TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cd555d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: on, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: co, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.4679\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.4679\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.6278\n",
      "✅ Removed Feature: on, New F1-Macro: 0.6480\n",
      "❌ Skipped Feature: co, F1-Macro: 0.6381\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5890\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6033\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5829\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5598\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5701\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5637\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5552\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5685\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5596\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5477\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5496\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6027\n",
      "✅ Removed Feature: words_per_clause, New F1-Macro: 0.6628\n",
      "✅ Removed Feature: short_pause, New F1-Macro: 0.6946\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5380\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5529\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.4679\n",
      "\n",
      "Final Selected Features: ['co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.6946\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6109 ± 0.1054\n",
      "Precision-Macro: 0.6098\n",
      "Recall-Macro: 0.6576\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.6586\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.6106\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6211\n",
      "❌ Skipped Feature: co, F1-Macro: 0.6246\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6039\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5888\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5976\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6058\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.6144\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5877\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5928\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5879\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6083\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6021\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5801\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6085\n",
      "✅ Removed Feature: words_per_clause, New F1-Macro: 0.6640\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.6262\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.6515\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.6479\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.6586\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.6640\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8162 ± 0.0944\n",
      "Precision-Macro: 0.7978\n",
      "Recall-Macro: 0.8737\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5085\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5085\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5389\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5211\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5046\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.4821\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.4980\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.4982\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5385\n",
      "✅ Removed Feature: verbs_with_inflections, New F1-Macro: 0.5526\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5206\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5523\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5486\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5386\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5295\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5345\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.5275\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5541\n",
      "✅ Removed Feature: mid_pause, New F1-Macro: 0.5767\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.4951\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5085\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5767\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6073 ± 0.1450\n",
      "Precision-Macro: 0.6077\n",
      "Recall-Macro: 0.6429\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4796\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5827\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5801\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5708\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5736\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5802\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5386\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5544\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5631\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5613\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5625\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5487\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5708\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5462\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5232\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5133\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4847\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4874\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5038\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.4796\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5827\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5827 ± 0.1110\n",
      "Precision-Macro: 0.5811\n",
      "Recall-Macro: 0.6308\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8078\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.7865\n",
      "❌ Skipped Feature: on, F1-Macro: 0.7944\n",
      "✅ Removed Feature: co, New F1-Macro: 0.8244\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.8194\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.8086\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.8021\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.7993\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.7913\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.8083\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.7899\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.7921\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.7739\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.7851\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.7775\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.7854\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.7990\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.7671\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.7950\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7874\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.8078\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.8244\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9159 ± 0.0601\n",
      "Precision-Macro: 0.9176\n",
      "Recall-Macro: 0.9199\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8082\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.7724\n",
      "❌ Skipped Feature: on, F1-Macro: 0.7647\n",
      "❌ Skipped Feature: co, F1-Macro: 0.7660\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.7439\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.7398\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.7489\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.7197\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.7324\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.7164\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.6687\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.6614\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6758\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6636\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.6459\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6636\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6930\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.7341\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.7517\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7639\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.8082\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.8082\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9256 ± 0.0449\n",
      "Precision-Macro: 0.9248\n",
      "Recall-Macro: 0.9310\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.7814\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.7890\n",
      "✅ Removed Feature: on, New F1-Macro: 0.7938\n",
      "✅ Removed Feature: co, New F1-Macro: 0.7988\n",
      "✅ Removed Feature: mean_sent_embs, New F1-Macro: 0.8033\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.7966\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.7936\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.7692\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.7706\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.7726\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.7599\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.7679\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.7705\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.7584\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.7913\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.8059\n",
      "✅ Removed Feature: words_per_clause, New F1-Macro: 0.8090\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.7966\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.7900\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7978\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.7814\n",
      "\n",
      "Final Selected Features: ['mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.8090\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8140 ± 0.0655\n",
      "Precision-Macro: 0.8137\n",
      "Recall-Macro: 0.8230\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5029\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5088\n",
      "✅ Removed Feature: on, New F1-Macro: 0.5120\n",
      "✅ Removed Feature: co, New F1-Macro: 0.5229\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.4967\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.4980\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5007\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5064\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5077\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5090\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5082\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.4870\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.4863\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.4831\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.4953\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.4905\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4822\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4809\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.4857\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5121\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5029\n",
      "\n",
      "Final Selected Features: ['mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5229\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5229 ± 0.0509\n",
      "Precision-Macro: 0.5089\n",
      "Recall-Macro: 0.5445\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5140\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5255\n",
      "❌ Skipped Feature: on, F1-Macro: 0.4973\n",
      "❌ Skipped Feature: co, F1-Macro: 0.4983\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.4783\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.4944\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.4605\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.4539\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.4772\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.4476\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.4560\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.4480\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.4621\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.4613\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.4380\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.4184\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4694\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4759\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.4607\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.4817\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5140\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5255\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5255 ± 0.0806\n",
      "Precision-Macro: 0.5486\n",
      "Recall-Macro: 0.5249\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5079\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5320\n",
      "✅ Removed Feature: on, New F1-Macro: 0.5442\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5396\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5228\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5252\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5356\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5384\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5174\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5190\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5198\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5133\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5274\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5326\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5412\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.5309\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5257\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5221\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5245\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5079\n",
      "\n",
      "Final Selected Features: ['co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5442\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5442 ± 0.0623\n",
      "Precision-Macro: 0.5494\n",
      "Recall-Macro: 0.5572\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        X_text = task_df[['speech']]  # Start with text only\n",
    "        y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "        baseline_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1, 1), max_features=5000, stop_words=stop_words), 'speech')\n",
    "        ])\n",
    "\n",
    "        baseline_pipeline = Pipeline([\n",
    "            ('preprocessor', baseline_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        # Baseline: TF-IDF only\n",
    "        baseline_score = cross_val_score(baseline_pipeline, X_text, y, cv=kf, scoring=f1_scorer).mean()\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Baseline (TF-IDF only) F1-Macro: {baseline_score:.4f}\")\n",
    "\n",
    "        # Feature selection loop\n",
    "        best_score = baseline_score\n",
    "        selected_features = numerical_features.copy()\n",
    "        current_features = selected_features.copy()\n",
    "        for feature in numerical_features:\n",
    "\n",
    "            current_features.remove(feature)\n",
    "\n",
    "            preprocessor = ColumnTransformer([\n",
    "                ('tfidf', tfidf, 'speech'),\n",
    "                ('num', StandardScaler(), current_features)\n",
    "            ])\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "\n",
    "            X_all = task_df[['speech'] + current_features]\n",
    "            new_score = cross_val_score(pipeline, X_all, y, cv=kf, scoring=f1_scorer).mean()\n",
    "\n",
    "            if new_score - best_score >= best_score * 0.01:\n",
    "                best_score = new_score\n",
    "                selected_features.remove(feature)\n",
    "                print(f\"✅ Removed Feature: {feature}, New F1-Macro: {new_score:.4f}\")\n",
    "            else:\n",
    "                print(f\"❌ Skipped Feature: {feature}, F1-Macro: {new_score:.4f}\")\n",
    "\n",
    "        print(f\"\\nFinal Selected Features: {selected_features}, Final F1-Macro: {best_score:.4f}\")\n",
    "\n",
    "        # Final evaluation with all selected features\n",
    "        final_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech'),\n",
    "            ('num', StandardScaler(), selected_features)\n",
    "        ]) if selected_features else ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech')\n",
    "        ])\n",
    "\n",
    "        final_pipeline = Pipeline([\n",
    "            ('preprocessor', final_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        X_final = task_df[['speech'] + selected_features] if selected_features else task_df[['speech']]\n",
    "\n",
    "        final_scores = cross_validate(final_pipeline, X_final, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"\\n🔎 Final Evaluation with Selected Features:\")\n",
    "        print(f\"F1-Macro: {final_scores['test_f1_macro'].mean():.4f} ± {final_scores['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {final_scores['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {final_scores['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": final_scores['test_f1_macro'].mean(),\n",
    "            \"Std F1\": final_scores['test_f1_macro'].std(),\n",
    "            \"Mean Precision Macro\": final_scores['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": final_scores['test_recall_macro'].mean(),\n",
    "            \"Type\": \"+\".join([\"TF-IDF\"] + selected_features) if selected_features else \"TF-IDF only\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86460f",
   "metadata": {},
   "source": [
    "# Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c0ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['mmse', 'short_pause']\n",
      "F1-Macro: 0.8273 ± 0.0572\n",
      "Precision-Macro: 0.8103\n",
      "Recall-Macro: 0.8914\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['mmse']\n",
      "F1-Macro: 0.8200 ± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "F1-Macro: 0.8170 ± 0.0721\n",
      "Precision-Macro: 0.7851\n",
      "Recall-Macro: 0.8916\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['on', 'co', 'mean_sent_embs', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'mmse', 'short_pause', 'mean_surprisal']\n",
      "F1-Macro: 0.8074 ± 0.0685\n",
      "Precision-Macro: 0.7798\n",
      "Recall-Macro: 0.8925\n",
      "F1-Macro: 0.7985 ± 0.0819\n",
      "Precision-Macro: 0.7744\n",
      "Recall-Macro: 0.8697\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['verbs_with_inflections', 'pid', 'mmse', 'mean_surprisal']\n",
      "F1-Macro: 0.6614 ± 0.1862\n",
      "Precision-Macro: 0.6930\n",
      "Recall-Macro: 0.6764\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['tree_depth', 'mmse']\n",
      "F1-Macro: 0.6099 ± 0.1224\n",
      "Precision-Macro: 0.6162\n",
      "Recall-Macro: 0.6632\n",
      "F1-Macro: 0.6021 ± 0.1433\n",
      "Precision-Macro: 0.6271\n",
      "Recall-Macro: 0.6061\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['pid_efficiency', 'words_per_clause', 'mmse', 'mid_pause']\n",
      "F1-Macro: 0.6349 ± 0.1542\n",
      "Precision-Macro: 0.6360\n",
      "Recall-Macro: 0.6825\n",
      "F1-Macro: 0.6515 ± 0.1887\n",
      "Precision-Macro: 0.6505\n",
      "Recall-Macro: 0.6821\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['on', 'co', 'nouns_with_determiners', 'pid_efficiency', 'frazier_score', 'mmse', 'long_pause']\n",
      "F1-Macro: 0.9650 ± 0.0280\n",
      "Precision-Macro: 0.9638\n",
      "Recall-Macro: 0.9688\n",
      "F1-Macro: 0.9308 ± 0.0480\n",
      "Precision-Macro: 0.9306\n",
      "Recall-Macro: 0.9351\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['on', 'mmse']\n",
      "F1-Macro: 0.9525 ± 0.0273\n",
      "Precision-Macro: 0.9520\n",
      "Recall-Macro: 0.9579\n",
      "F1-Macro: 0.9573 ± 0.0327\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9627\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['mlu', 'mmse']\n",
      "F1-Macro: 0.9575 ± 0.0327\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9640\n",
      "F1-Macro: 0.9551 ± 0.0339\n",
      "Precision-Macro: 0.9540\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    all_numeric = task_df.select_dtypes(include=[np.number]).drop(columns=['speaking time (s)']).columns.tolist()\n",
    "\n",
    "    X_num_all = task_df[all_numeric].values\n",
    "    numeric_feature_names = all_numeric\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        sfs = SFS(\n",
    "            estimator=clone(model),\n",
    "            k_features='best',\n",
    "            floating=True,\n",
    "            scoring=f1_macro_scorer,\n",
    "            cv=kf,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        sfs = sfs.fit(X_num_all, y)\n",
    "        selected_idx = list(sfs.k_feature_idx_)\n",
    "        selected_features = [numeric_feature_names[i] for i in selected_idx]\n",
    "        X_selected = task_df[selected_features]\n",
    "        print(\"Selected numeric features: \", selected_features)\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), selected_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X_selected, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"+\".join(selected_features),\n",
    "        })\n",
    "\n",
    "        ### TF-IDF + Selected Features\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "                ('num', StandardScaler(), selected_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        X_selected = task_df[['speech'] + selected_features]\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X_selected, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"+\".join([\"TF-IDF\"] + selected_features)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0c861",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5e5ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a1f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.read_csv(\"/Users/kirillkonca/Documents/dementia_prediction/src/classification/all_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e67abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame(results)\n",
    "# all_results.to_csv(\"all_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad6093b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.571365</td>\n",
       "      <td>0.606726</td>\n",
       "      <td>0.613954</td>\n",
       "      <td>0.112546</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.616925</td>\n",
       "      <td>0.665836</td>\n",
       "      <td>0.640670</td>\n",
       "      <td>0.150424</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Task                Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "0       MCI vs. AD        Random Forest       0.820021              0.778155   \n",
       "1       MCI vs. AD                  SVM       0.820021              0.778155   \n",
       "2       MCI vs. AD  Logistic Regression       0.820021              0.778155   \n",
       "3  MCI vs. Control        Random Forest       0.571365              0.606726   \n",
       "4  MCI vs. Control                  SVM       0.616925              0.665836   \n",
       "\n",
       "   Mean Recall Macro    Std F1  Type  \n",
       "0           0.931896  0.074311  MMSE  \n",
       "1           0.931896  0.074311  MMSE  \n",
       "2           0.931896  0.074311  MMSE  \n",
       "3           0.613954  0.112546  MMSE  \n",
       "4           0.640670  0.150424  MMSE  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe8489be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[all_results[\"Model\"] == \"SVM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9492fabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.962242</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.968169</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.843426</td>\n",
       "      <td>0.809513</td>\n",
       "      <td>0.920100</td>\n",
       "      <td>0.086444</td>\n",
       "      <td>TF-IDF+mmse+on+stop_words+frazier_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.740903</td>\n",
       "      <td>0.751815</td>\n",
       "      <td>0.773452</td>\n",
       "      <td>0.079807</td>\n",
       "      <td>TF-IDF+mmse+co+verbs_with_inflections+short_pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.685734</td>\n",
       "      <td>0.711041</td>\n",
       "      <td>0.673876</td>\n",
       "      <td>0.195618</td>\n",
       "      <td>TF-IDF+mmse+sid+mean_surprisal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Task Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "31          AD vs. Control   SVM       0.962242              0.961029   \n",
       "73              MCI vs. AD   SVM       0.843426              0.809513   \n",
       "82  MCI vs. AD vs. Control   SVM       0.740903              0.751815   \n",
       "76         MCI vs. Control   SVM       0.685734              0.711041   \n",
       "\n",
       "    Mean Recall Macro    Std F1  \\\n",
       "31           0.968169  0.031528   \n",
       "73           0.920100  0.086444   \n",
       "82           0.773452  0.079807   \n",
       "76           0.673876  0.195618   \n",
       "\n",
       "                                                 Type  \n",
       "31                                      TF-IDF + MMSE  \n",
       "73            TF-IDF+mmse+on+stop_words+frazier_score  \n",
       "82  TF-IDF+mmse+co+verbs_with_inflections+short_pause  \n",
       "76                     TF-IDF+mmse+sid+mean_surprisal  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.loc[all_results.groupby(\"Task\")[\"Mean F1 Macro\"].idxmax()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
