{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bf877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7705db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e64ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/kirillkonca/Documents/dementia_prediction/data_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c2c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average=\"macro\", zero_division=0)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = list(stop_words)\n",
    "scoring = {\n",
    "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'recall_macro': make_scorer(recall_score, average='macro', zero_division=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6648bd",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a2b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ca56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MCI vs. AD\": df[df['diagnosis'].isin(['MCI', 'AD'])],\n",
    "    \"MCI vs. Control\": df[df['diagnosis'].isin(['MCI', 'Control'])],\n",
    "    \"MCI vs. AD vs. Control\": df\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"SVM\": SVC(random_state=42, class_weight='balanced'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21706725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "SHAP plot saved to: shap_plots/shap_MCI_vs._AD.png\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "SHAP plot saved to: shap_plots/shap_MCI_vs._Control.png\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "SHAP plot saved to: shap_plots/shap_MCI_vs._AD_vs._Control.png\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ----- PARAMETERS -----\n",
    "numerical_cols_by_task = {\n",
    "    \"MCI vs. AD\": ['stop_words', 'short_pause', 'mean_surprisal'],\n",
    "    \"MCI vs. Control\": ['mean_surprisal'],\n",
    "    \"MCI vs. AD vs. Control\": ['co', 'mean_surprisal']\n",
    "}\n",
    "output_dir = \"shap_plots\"\n",
    "import os\n",
    "os.mkdir(\"shap_plots\")\n",
    "n_tfidf_components = 1  # or more if desired\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ----- LOOP THROUGH TASKS -----\n",
    "features_used = {}\n",
    "\n",
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    # Select relevant numerical columns\n",
    "    numerical_cols = numerical_cols_by_task[task_name]\n",
    "    features_used[task_name] = ['TF-IDF'] + numerical_cols\n",
    "\n",
    "    X = task_df[['speech'] + numerical_cols].copy()\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    # --- Pipelines ---\n",
    "    tfidf_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words)),\n",
    "        ('svd', TruncatedSVD(n_components=n_tfidf_components, random_state=42))\n",
    "    ])\n",
    "\n",
    "    text_transformer = FunctionTransformer(lambda x: x['speech'], validate=False)\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('tfidf', Pipeline([\n",
    "            ('extract', text_transformer),\n",
    "            ('tfidf', tfidf_pipeline)\n",
    "        ]), ['speech']),\n",
    "        ('num', Pipeline([\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_cols)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', SVC(probability=True, kernel='linear', class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "\n",
    "    # --- Train on full data (or optionally cross-val inside loop) ---\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    # --- SHAP Analysis ---\n",
    "    X_preprocessed = pipeline.named_steps['preprocess'].transform(X)\n",
    "    explainer = shap.Explainer(pipeline.named_steps['clf'], X_preprocessed)\n",
    "    shap_values = explainer(X_preprocessed)\n",
    "\n",
    "    # --- Save SHAP Plot ---\n",
    "    plt.figure()\n",
    "    shap.summary_plot(\n",
    "        shap_values,\n",
    "        features=X_preprocessed,\n",
    "        feature_names=features_used[task_name],\n",
    "        show=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plot_path = f\"{output_dir}/shap_{task_name.replace(' ', '_').replace('/', '_')}.png\"\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"SHAP plot saved to: {plot_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d953b9",
   "metadata": {},
   "source": [
    "## MMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4d65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.8200 ± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8200 ± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8200 ± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5714 ± 0.1125\n",
      "Precision-Macro: 0.6067\n",
      "Recall-Macro: 0.6140\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6169 ± 0.1504\n",
      "Precision-Macro: 0.6658\n",
      "Recall-Macro: 0.6407\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6109 ± 0.1687\n",
      "Precision-Macro: 0.6256\n",
      "Recall-Macro: 0.6503\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9575 ± 0.0327\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9640\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9550 ± 0.0321\n",
      "Precision-Macro: 0.9552\n",
      "Recall-Macro: 0.9603\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9571 ± 0.0401\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.6755 ± 0.0696\n",
      "Precision-Macro: 0.7061\n",
      "Recall-Macro: 0.7279\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6951 ± 0.0567\n",
      "Precision-Macro: 0.7134\n",
      "Recall-Macro: 0.7616\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6951 ± 0.0567\n",
      "Precision-Macro: 0.7134\n",
      "Recall-Macro: 0.7616\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df[['mmse']].values\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        cv_results = cross_validate(model, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"MMSE\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d0a23",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e91f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6586 ± 0.1372\n",
      "Precision-Macro: 0.6785\n",
      "Recall-Macro: 0.6610\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.4796 ± 0.0915\n",
      "Precision-Macro: 0.4756\n",
      "Recall-Macro: 0.4958\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.8078 ± 0.0699\n",
      "Precision-Macro: 0.8111\n",
      "Recall-Macro: 0.8112\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8082 ± 0.0576\n",
      "Precision-Macro: 0.8120\n",
      "Recall-Macro: 0.8151\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.7814 ± 0.0580\n",
      "Precision-Macro: 0.7875\n",
      "Recall-Macro: 0.7906\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5029 ± 0.0276\n",
      "Precision-Macro: 0.4910\n",
      "Recall-Macro: 0.5239\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5140 ± 0.0206\n",
      "Precision-Macro: 0.4968\n",
      "Recall-Macro: 0.5381\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5079 ± 0.0340\n",
      "Precision-Macro: 0.5004\n",
      "Recall-Macro: 0.5217\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df['speech']\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words)),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"TF-IDF + MMSE\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58a146",
   "metadata": {},
   "source": [
    "## TF-IDF + MMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2cdf1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8170 ± 0.0721\n",
      "Precision-Macro: 0.7851\n",
      "Recall-Macro: 0.8916\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8357 ± 0.0816\n",
      "Precision-Macro: 0.7966\n",
      "Recall-Macro: 0.9386\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6503 ± 0.1624\n",
      "Precision-Macro: 0.7113\n",
      "Recall-Macro: 0.6416\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6218 ± 0.1890\n",
      "Precision-Macro: 0.6314\n",
      "Recall-Macro: 0.6372\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9257 ± 0.0444\n",
      "Precision-Macro: 0.9297\n",
      "Recall-Macro: 0.9282\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9622 ± 0.0315\n",
      "Precision-Macro: 0.9610\n",
      "Recall-Macro: 0.9682\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9551 ± 0.0339\n",
      "Precision-Macro: 0.9540\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5972 ± 0.0315\n",
      "Precision-Macro: 0.5778\n",
      "Recall-Macro: 0.6240\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6640 ± 0.0767\n",
      "Precision-Macro: 0.6686\n",
      "Recall-Macro: 0.6736\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6872 ± 0.0876\n",
      "Precision-Macro: 0.7010\n",
      "Recall-Macro: 0.6910\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df[['speech', 'mmse']]\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    # Define column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "            ('mmse', StandardScaler(), ['mmse'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"TF-IDF + MMSE\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ceaa035",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "129f4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.571365</td>\n",
       "      <td>0.606726</td>\n",
       "      <td>0.613954</td>\n",
       "      <td>0.112546</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.616925</td>\n",
       "      <td>0.665836</td>\n",
       "      <td>0.640670</td>\n",
       "      <td>0.150424</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Task                Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "0       MCI vs. AD        Random Forest       0.820021              0.778155   \n",
       "1       MCI vs. AD                  SVM       0.820021              0.778155   \n",
       "2       MCI vs. AD  Logistic Regression       0.820021              0.778155   \n",
       "3  MCI vs. Control        Random Forest       0.571365              0.606726   \n",
       "4  MCI vs. Control                  SVM       0.616925              0.665836   \n",
       "\n",
       "   Mean Recall Macro    Std F1  Type  \n",
       "0           0.931896  0.074311  MMSE  \n",
       "1           0.931896  0.074311  MMSE  \n",
       "2           0.931896  0.074311  MMSE  \n",
       "3           0.613954  0.112546  MMSE  \n",
       "4           0.640670  0.150424  MMSE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97318c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.962242</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.968169</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.835719</td>\n",
       "      <td>0.796607</td>\n",
       "      <td>0.938616</td>\n",
       "      <td>0.081554</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.695081</td>\n",
       "      <td>0.713441</td>\n",
       "      <td>0.761550</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.650258</td>\n",
       "      <td>0.711317</td>\n",
       "      <td>0.641573</td>\n",
       "      <td>0.162386</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Task                Model  Mean F1 Macro  \\\n",
       "31          AD vs. Control                  SVM       0.962242   \n",
       "26              MCI vs. AD  Logistic Regression       0.835719   \n",
       "10  MCI vs. AD vs. Control                  SVM       0.695081   \n",
       "28         MCI vs. Control                  SVM       0.650258   \n",
       "\n",
       "    Mean Precision Macro  Mean Recall Macro    Std F1           Type  \n",
       "31              0.961029           0.968169  0.031528  TF-IDF + MMSE  \n",
       "26              0.796607           0.938616  0.081554  TF-IDF + MMSE  \n",
       "10              0.713441           0.761550  0.056706           MMSE  \n",
       "28              0.711317           0.641573  0.162386  TF-IDF + MMSE  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_results.loc[baselines_results.groupby('Task')['Mean F1 Macro'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ae63c",
   "metadata": {},
   "source": [
    "# All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de4dfbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.6058 ± 0.1302\n",
      "Precision-Macro: 0.6743\n",
      "Recall-Macro: 0.5952\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.7455 ± 0.1045\n",
      "Precision-Macro: 0.7414\n",
      "Recall-Macro: 0.7897\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8396 ± 0.0774\n",
      "Precision-Macro: 0.8221\n",
      "Recall-Macro: 0.9031\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4561 ± 0.0199\n",
      "Precision-Macro: 0.4251\n",
      "Recall-Macro: 0.4955\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6109 ± 0.0998\n",
      "Precision-Macro: 0.6205\n",
      "Recall-Macro: 0.6576\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6025 ± 0.1099\n",
      "Precision-Macro: 0.6027\n",
      "Recall-Macro: 0.6737\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9426 ± 0.0341\n",
      "Precision-Macro: 0.9416\n",
      "Recall-Macro: 0.9471\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9210 ± 0.0394\n",
      "Precision-Macro: 0.9206\n",
      "Recall-Macro: 0.9251\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9473 ± 0.0390\n",
      "Precision-Macro: 0.9467\n",
      "Recall-Macro: 0.9522\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.6090 ± 0.0243\n",
      "Precision-Macro: 0.5879\n",
      "Recall-Macro: 0.6364\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6509 ± 0.0931\n",
      "Precision-Macro: 0.6644\n",
      "Recall-Macro: 0.6585\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6777 ± 0.0681\n",
      "Precision-Macro: 0.6889\n",
      "Recall-Macro: 0.7020\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    features_columns = task_df.select_dtypes(include=[np.number]).drop(columns=['speaking time (s)']).columns.tolist()\n",
    "    # features_columns.remove('mmse')\n",
    "    X = task_df[features_columns]\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"All Features\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3acbc",
   "metadata": {},
   "source": [
    "# TF-IDF + All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50821151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.7455 ± 0.1045\n",
      "Precision-Macro: 0.7414\n",
      "Recall-Macro: 0.7897\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8143 ± 0.0875\n",
      "Precision-Macro: 0.7981\n",
      "Recall-Macro: 0.8738\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6063 ± 0.0971\n",
      "Precision-Macro: 0.6217\n",
      "Recall-Macro: 0.6507\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6080 ± 0.1050\n",
      "Precision-Macro: 0.6050\n",
      "Recall-Macro: 0.6620\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9309 ± 0.0314\n",
      "Precision-Macro: 0.9319\n",
      "Recall-Macro: 0.9326\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9210 ± 0.0394\n",
      "Precision-Macro: 0.9206\n",
      "Recall-Macro: 0.9251\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9498 ± 0.0368\n",
      "Precision-Macro: 0.9490\n",
      "Recall-Macro: 0.9550\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.6019 ± 0.0211\n",
      "Precision-Macro: 0.5835\n",
      "Recall-Macro: 0.6253\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6431 ± 0.0978\n",
      "Precision-Macro: 0.6438\n",
      "Recall-Macro: 0.6567\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.7016 ± 0.0836\n",
      "Precision-Macro: 0.6929\n",
      "Recall-Macro: 0.7276\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    features_columns = task_df.select_dtypes(include=[np.number]).drop(columns=['speaking time (s)']).columns.tolist()\n",
    "    X = task_df[['speech'] + features_columns]\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    # Define column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "            ('num', StandardScaler(), features_columns)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"All Features\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c4097",
   "metadata": {},
   "source": [
    "# Linear Feature Addition to TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1657f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features.remove(\"speaking time (s)\")\n",
    "numerical_features.remove(\"mmse\")  # mmse will be added manually at the start\n",
    "numerical_features.insert(0, \"mmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4670501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: on, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: co, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.4679\n",
      "\n",
      "Final Selected Features: [], Final F1-Macro: 0.4679\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.8170\n",
      "❌ Skipped Feature: on, F1-Macro: 0.8250\n",
      "❌ Skipped Feature: co, F1-Macro: 0.8200\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.8249\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.7982\n",
      "✅ Added Feature: stop_words, New F1-Macro: 0.8293\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.7961\n",
      "✅ Added Feature: verbs_with_inflections, New F1-Macro: 0.8398\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.7978\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.8106\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.7940\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.8146\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.8078\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.8299\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.8264\n",
      "✅ Added Feature: words_per_clause, New F1-Macro: 0.8493\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.8358\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.8140\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.8134\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.8438\n",
      "\n",
      "Final Selected Features: ['mmse', 'stop_words', 'verbs_with_inflections', 'words_per_clause'], Final F1-Macro: 0.8493\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8493 ± 0.0816\n",
      "Precision-Macro: 0.8213\n",
      "Recall-Macro: 0.9226\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.6586\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.8357\n",
      "❌ Skipped Feature: on, F1-Macro: 0.8293\n",
      "❌ Skipped Feature: co, F1-Macro: 0.8291\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.8244\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.8254\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.8274\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.8163\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.8291\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.8282\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.8210\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.8293\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.8293\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.8357\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.8376\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.8144\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.8357\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.8438\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.8293\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.8291\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.8397\n",
      "\n",
      "Final Selected Features: ['mmse'], Final F1-Macro: 0.8357\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8357 ± 0.0816\n",
      "Precision-Macro: 0.7966\n",
      "Recall-Macro: 0.9386\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5085\n",
      "\n",
      "Final Selected Features: [], Final F1-Macro: 0.5085\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.6503\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6364\n",
      "❌ Skipped Feature: co, F1-Macro: 0.6533\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6259\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6024\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.6498\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6021\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.6270\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.6023\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.6555\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.6284\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6460\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6359\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.6549\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6364\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6264\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.6258\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5930\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.6289\n",
      "✅ Added Feature: mean_surprisal, New F1-Macro: 0.7045\n",
      "\n",
      "Final Selected Features: ['mmse', 'mean_surprisal'], Final F1-Macro: 0.7045\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.7045 ± 0.1847\n",
      "Precision-Macro: 0.7447\n",
      "Recall-Macro: 0.6881\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4796\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.6218\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6174\n",
      "✅ Added Feature: co, New F1-Macro: 0.6470\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6456\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6468\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.6337\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6469\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.6372\n",
      "✅ Added Feature: nouns_with_determiners, New F1-Macro: 0.6570\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.6590\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.6571\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6431\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6506\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.6486\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6498\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6517\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.6604\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.6512\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.6495\n",
      "✅ Added Feature: mean_surprisal, New F1-Macro: 0.6690\n",
      "\n",
      "Final Selected Features: ['mmse', 'co', 'nouns_with_determiners', 'mean_surprisal'], Final F1-Macro: 0.6690\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6690 ± 0.1608\n",
      "Precision-Macro: 0.6737\n",
      "Recall-Macro: 0.7050\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8078\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.9257\n",
      "❌ Skipped Feature: on, F1-Macro: 0.9306\n",
      "❌ Skipped Feature: co, F1-Macro: 0.9307\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.9257\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.9331\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.9304\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.9257\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.9159\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.9327\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.9234\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.9329\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.9233\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.9256\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.9307\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.9330\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.9282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added Feature: short_pause, New F1-Macro: 0.9406\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.9138\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.9207\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.9256\n",
      "\n",
      "Final Selected Features: ['mmse', 'short_pause'], Final F1-Macro: 0.9406\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9406 ± 0.0560\n",
      "Precision-Macro: 0.9423\n",
      "Recall-Macro: 0.9442\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8082\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.9622\n",
      "❌ Skipped Feature: on, F1-Macro: 0.9573\n",
      "❌ Skipped Feature: co, F1-Macro: 0.9622\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.9574\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.9623\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.9598\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.9623\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.9599\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.9574\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.9598\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.9550\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.9598\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.9599\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.9475\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.9573\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.9549\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.9526\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.9576\n",
      "\n",
      "Final Selected Features: ['mmse'], Final F1-Macro: 0.9622\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9622 ± 0.0315\n",
      "Precision-Macro: 0.9610\n",
      "Recall-Macro: 0.9682\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.7814\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.9551\n",
      "❌ Skipped Feature: on, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: co, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.9550\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.9501\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.9525\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.9575\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.9527\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.9526\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.9551\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.9526\n",
      "\n",
      "Final Selected Features: ['mmse'], Final F1-Macro: 0.9551\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9551 ± 0.0339\n",
      "Precision-Macro: 0.9540\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5029\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.5972\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6026\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5915\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5955\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5941\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5980\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5988\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5978\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5964\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5926\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5955\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5909\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5961\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5989\n",
      "✅ Added Feature: frazier_score, New F1-Macro: 0.6076\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6041\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5983\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5956\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.6036\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5973\n",
      "\n",
      "Final Selected Features: ['mmse', 'frazier_score'], Final F1-Macro: 0.6076\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6076 ± 0.0254\n",
      "Precision-Macro: 0.5865\n",
      "Recall-Macro: 0.6335\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5140\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.6640\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6444\n",
      "✅ Added Feature: co, New F1-Macro: 0.7130\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.7020\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6349\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.7065\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6360\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.6989\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.6735\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.6535\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.7043\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6502\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6929\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.7132\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6607\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6856\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.7015\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.6884\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.6856\n",
      "✅ Added Feature: mean_surprisal, New F1-Macro: 0.7542\n",
      "\n",
      "Final Selected Features: ['mmse', 'co', 'mean_surprisal'], Final F1-Macro: 0.7542\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.7542 ± 0.0830\n",
      "Precision-Macro: 0.7597\n",
      "Recall-Macro: 0.7728\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5079\n",
      "✅ Added Feature: mmse, New F1-Macro: 0.6872\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6769\n",
      "✅ Added Feature: co, New F1-Macro: 0.6945\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6844\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6982\n",
      "✅ Added Feature: stop_words, New F1-Macro: 0.7198\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6916\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.6593\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.6675\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.7038\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.7039\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6966\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.7189\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.7150\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.7232\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6961\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.6903\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.7000\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7052\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.7134\n",
      "\n",
      "Final Selected Features: ['mmse', 'co', 'stop_words'], Final F1-Macro: 0.7198\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.7198 ± 0.0971\n",
      "Precision-Macro: 0.7277\n",
      "Recall-Macro: 0.7233\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        X_text = task_df[['speech']]  # Start with text only\n",
    "        y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "        # Define TF-IDF for baseline\n",
    "        tfidf = TfidfVectorizer(ngram_range=(1, 1), max_features=5000, stop_words=stop_words)\n",
    "\n",
    "        baseline_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech')\n",
    "        ])\n",
    "\n",
    "        baseline_pipeline = Pipeline([\n",
    "            ('preprocessor', baseline_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        # Baseline: TF-IDF only\n",
    "        baseline_score = cross_val_score(baseline_pipeline, X_text, y, cv=kf, scoring=f1_scorer).mean()\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Baseline (TF-IDF only) F1-Macro: {baseline_score:.4f}\")\n",
    "\n",
    "        # Feature selection loop\n",
    "        best_score = baseline_score\n",
    "        selected_features = []\n",
    "\n",
    "        for feature in numerical_features:\n",
    "\n",
    "            current_features = selected_features + [feature]\n",
    "\n",
    "            preprocessor = ColumnTransformer([\n",
    "                ('tfidf', tfidf, 'speech'),\n",
    "                ('num', StandardScaler(), current_features)\n",
    "            ])\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "\n",
    "            X_all = task_df[['speech'] + current_features]\n",
    "            new_score = cross_val_score(pipeline, X_all, y, cv=kf, scoring=f1_scorer).mean()\n",
    "\n",
    "            if new_score - best_score >= best_score * 0.01:\n",
    "                best_score = new_score\n",
    "                selected_features.append(feature)\n",
    "                print(f\"✅ Added Feature: {feature}, New F1-Macro: {new_score:.4f}\")\n",
    "            else:\n",
    "                print(f\"❌ Skipped Feature: {feature}, F1-Macro: {new_score:.4f}\")\n",
    "\n",
    "        print(f\"\\nFinal Selected Features: {selected_features}, Final F1-Macro: {best_score:.4f}\")\n",
    "\n",
    "        # Final evaluation with all selected features\n",
    "        final_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech'),\n",
    "            ('num', StandardScaler(), selected_features)\n",
    "        ]) if selected_features else ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech')\n",
    "        ])\n",
    "\n",
    "        final_pipeline = Pipeline([\n",
    "            ('preprocessor', final_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        X_final = task_df[['speech'] + selected_features] if selected_features else task_df[['speech']]\n",
    "\n",
    "        final_scores = cross_validate(final_pipeline, X_final, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"\\n🔎 Final Evaluation with Selected Features:\")\n",
    "        print(f\"F1-Macro: {final_scores['test_f1_macro'].mean():.4f} ± {final_scores['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {final_scores['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {final_scores['test_recall_macro'].mean():.4f}\")\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": final_scores['test_f1_macro'].mean(),\n",
    "            \"Std F1\": final_scores['test_f1_macro'].std(),\n",
    "            \"Mean Precision Macro\": final_scores['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": final_scores['test_recall_macro'].mean(),\n",
    "            \"Type\": \"+\".join([\"TF-IDF\"] + selected_features) if selected_features else \"TF-IDF only\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e871a",
   "metadata": {},
   "source": [
    "# Linear Feature Deletion from TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cd555d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: on, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: co, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.4679\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.4679\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.4679\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.6424\n",
      "✅ Removed Feature: on, New F1-Macro: 0.6598\n",
      "❌ Skipped Feature: co, F1-Macro: 0.6514\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6421\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6416\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.6281\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6096\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5701\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5637\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5552\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5685\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5596\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5477\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5496\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6027\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6628\n",
      "✅ Removed Feature: short_pause, New F1-Macro: 0.6946\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5380\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5529\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.4679\n",
      "\n",
      "Final Selected Features: ['co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.6946\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6568 ± 0.0889\n",
      "Precision-Macro: 0.6468\n",
      "Recall-Macro: 0.7053\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.6586\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.6167\n",
      "❌ Skipped Feature: on, F1-Macro: 0.6272\n",
      "❌ Skipped Feature: co, F1-Macro: 0.6276\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.6046\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.6021\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.6116\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.6161\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.6144\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5877\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5928\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5879\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6083\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6021\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5801\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6085\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6640\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.6262\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.6515\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.6479\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.6586\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.6586\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8143 ± 0.0875\n",
      "Precision-Macro: 0.7981\n",
      "Recall-Macro: 0.8738\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5085\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5085\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5729\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5617\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5503\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.4611\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5132\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.4945\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5373\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5526\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5206\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5523\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5486\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5386\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5295\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5345\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5085\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.5275\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5541\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5767\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.4951\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5085\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5729\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5729 ± 0.1126\n",
      "Precision-Macro: 0.5800\n",
      "Recall-Macro: 0.6059\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4796\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5953\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5905\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5860\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5809\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5920\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5344\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5711\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5631\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5613\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5625\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5487\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5708\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5462\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5232\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5133\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4874\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5066\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5038\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.4796\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5953\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5953 ± 0.1178\n",
      "Precision-Macro: 0.5898\n",
      "Recall-Macro: 0.6421\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8078\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.8076\n",
      "❌ Skipped Feature: on, F1-Macro: 0.7987\n",
      "✅ Removed Feature: co, New F1-Macro: 0.8432\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.8033\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.8155\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.7938\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.7992\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.7913\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.8083\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.7899\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.7921\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.7739\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.7851\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.7775\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.7854\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.7990\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.7671\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.7950\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7874\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.8078\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.8432\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9183 ± 0.0619\n",
      "Precision-Macro: 0.9197\n",
      "Recall-Macro: 0.9223\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8082\n",
      "❌ Skipped Feature: mmse, F1-Macro: 0.7622\n",
      "❌ Skipped Feature: on, F1-Macro: 0.7644\n",
      "❌ Skipped Feature: co, F1-Macro: 0.7616\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.7416\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.7518\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.7420\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.7021\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.7324\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.7164\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.6687\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.6614\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.6758\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.6636\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.6459\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.6636\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.6930\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.7341\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.7517\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7639\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.8082\n",
      "\n",
      "Final Selected Features: ['mmse', 'on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.8082\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.9210 ± 0.0394\n",
      "Precision-Macro: 0.9206\n",
      "Recall-Macro: 0.9251\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.7814\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.7933\n",
      "✅ Removed Feature: on, New F1-Macro: 0.8056\n",
      "❌ Skipped Feature: co, F1-Macro: 0.8031\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.7939\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.7965\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.7913\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.7720\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.7706\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.7726\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.7599\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.7679\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.7705\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.7584\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.7913\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.8059\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.8090\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.7966\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.7900\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.7978\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.7814\n",
      "\n",
      "Final Selected Features: ['co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.8056\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8056 ± 0.0636\n",
      "Precision-Macro: 0.8086\n",
      "Recall-Macro: 0.8137\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5029\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5310\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5158\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5147\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5058\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.4994\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5043\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.4920\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5077\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5090\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5082\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.4870\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.4863\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.4831\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.4953\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.4905\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4822\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4809\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.4857\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5121\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5029\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5310\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5310 ± 0.0328\n",
      "Precision-Macro: 0.5152\n",
      "Recall-Macro: 0.5516\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5140\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5350\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5187\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5118\n",
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5053\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5036\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5016\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.4957\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.4772\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.4476\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.4560\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.4480\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.4621\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.4613\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.4380\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.4184\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.4694\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.4759\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.4607\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.4817\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5140\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5350\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5350 ± 0.0621\n",
      "Precision-Macro: 0.5479\n",
      "Recall-Macro: 0.5364\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5079\n",
      "✅ Removed Feature: mmse, New F1-Macro: 0.5390\n",
      "❌ Skipped Feature: on, F1-Macro: 0.5424\n",
      "❌ Skipped Feature: co, F1-Macro: 0.5350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Skipped Feature: mean_sent_embs, F1-Macro: 0.5295\n",
      "❌ Skipped Feature: mlu, F1-Macro: 0.5279\n",
      "❌ Skipped Feature: stop_words, F1-Macro: 0.5204\n",
      "❌ Skipped Feature: tree_depth, F1-Macro: 0.5377\n",
      "❌ Skipped Feature: verbs_with_inflections, F1-Macro: 0.5384\n",
      "❌ Skipped Feature: nouns_with_determiners, F1-Macro: 0.5174\n",
      "❌ Skipped Feature: sid, F1-Macro: 0.5190\n",
      "❌ Skipped Feature: sid_efficiency, F1-Macro: 0.5198\n",
      "❌ Skipped Feature: pid, F1-Macro: 0.5133\n",
      "❌ Skipped Feature: pid_efficiency, F1-Macro: 0.5274\n",
      "❌ Skipped Feature: maas, F1-Macro: 0.5326\n",
      "❌ Skipped Feature: frazier_score, F1-Macro: 0.5412\n",
      "❌ Skipped Feature: words_per_clause, F1-Macro: 0.5309\n",
      "❌ Skipped Feature: short_pause, F1-Macro: 0.5257\n",
      "❌ Skipped Feature: mid_pause, F1-Macro: 0.5221\n",
      "❌ Skipped Feature: long_pause, F1-Macro: 0.5245\n",
      "❌ Skipped Feature: mean_surprisal, F1-Macro: 0.5079\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5390\n",
      "\n",
      "🔎 Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5390 ± 0.0691\n",
      "Precision-Macro: 0.5390\n",
      "Recall-Macro: 0.5541\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        X_text = task_df[['speech']]  # Start with text only\n",
    "        y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "        baseline_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1, 1), max_features=5000, stop_words=stop_words), 'speech')\n",
    "        ])\n",
    "\n",
    "        baseline_pipeline = Pipeline([\n",
    "            ('preprocessor', baseline_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        # Baseline: TF-IDF only\n",
    "        baseline_score = cross_val_score(baseline_pipeline, X_text, y, cv=kf, scoring=f1_scorer).mean()\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Baseline (TF-IDF only) F1-Macro: {baseline_score:.4f}\")\n",
    "\n",
    "        # Feature selection loop\n",
    "        best_score = baseline_score\n",
    "        selected_features = numerical_features.copy()\n",
    "        current_features = selected_features.copy()\n",
    "        for feature in numerical_features:\n",
    "\n",
    "            current_features.remove(feature)\n",
    "\n",
    "            preprocessor = ColumnTransformer([\n",
    "                ('tfidf', tfidf, 'speech'),\n",
    "                ('num', StandardScaler(), current_features)\n",
    "            ])\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "\n",
    "            X_all = task_df[['speech'] + current_features]\n",
    "            new_score = cross_val_score(pipeline, X_all, y, cv=kf, scoring=f1_scorer).mean()\n",
    "\n",
    "            if new_score - best_score >= best_score * 0.01:\n",
    "                best_score = new_score\n",
    "                selected_features.remove(feature)\n",
    "                print(f\"✅ Removed Feature: {feature}, New F1-Macro: {new_score:.4f}\")\n",
    "            else:\n",
    "                print(f\"❌ Skipped Feature: {feature}, F1-Macro: {new_score:.4f}\")\n",
    "\n",
    "        print(f\"\\nFinal Selected Features: {selected_features}, Final F1-Macro: {best_score:.4f}\")\n",
    "\n",
    "        # Final evaluation with all selected features\n",
    "        final_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech'),\n",
    "            ('num', StandardScaler(), selected_features)\n",
    "        ]) if selected_features else ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech')\n",
    "        ])\n",
    "\n",
    "        final_pipeline = Pipeline([\n",
    "            ('preprocessor', final_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        X_final = task_df[['speech'] + selected_features] if selected_features else task_df[['speech']]\n",
    "\n",
    "        final_scores = cross_validate(final_pipeline, X_final, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"\\n🔎 Final Evaluation with Selected Features:\")\n",
    "        print(f\"F1-Macro: {final_scores['test_f1_macro'].mean():.4f} ± {final_scores['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {final_scores['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {final_scores['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": final_scores['test_f1_macro'].mean(),\n",
    "            \"Std F1\": final_scores['test_f1_macro'].std(),\n",
    "            \"Mean Precision Macro\": final_scores['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": final_scores['test_recall_macro'].mean(),\n",
    "            \"Type\": \"+\".join([\"TF-IDF\"] + selected_features) if selected_features else \"TF-IDF only\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86460f",
   "metadata": {},
   "source": [
    "# Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "515c0ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['mmse', 'short_pause']\n",
      "F1-Macro: 0.8273 ± 0.0572\n",
      "Precision-Macro: 0.8103\n",
      "Recall-Macro: 0.8914\n",
      "F1-Macro: 0.4679 ± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['mmse']\n",
      "F1-Macro: 0.8200 ± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "F1-Macro: 0.8170 ± 0.0721\n",
      "Precision-Macro: 0.7851\n",
      "Recall-Macro: 0.8916\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['on', 'co', 'mean_sent_embs', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'mmse', 'short_pause', 'mean_surprisal']\n",
      "F1-Macro: 0.7955 ± 0.0773\n",
      "Precision-Macro: 0.7750\n",
      "Recall-Macro: 0.8672\n",
      "F1-Macro: 0.8357 ± 0.0816\n",
      "Precision-Macro: 0.7966\n",
      "Recall-Macro: 0.9386\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['stop_words', 'pid', 'pid_efficiency', 'mmse', 'mean_surprisal']\n",
      "F1-Macro: 0.6376 ± 0.2110\n",
      "Precision-Macro: 0.6887\n",
      "Recall-Macro: 0.6436\n",
      "F1-Macro: 0.5085 ± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['tree_depth', 'mmse']\n",
      "F1-Macro: 0.6099 ± 0.1224\n",
      "Precision-Macro: 0.6162\n",
      "Recall-Macro: 0.6632\n",
      "F1-Macro: 0.6503 ± 0.1624\n",
      "Precision-Macro: 0.7113\n",
      "Recall-Macro: 0.6416\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['pid_efficiency', 'words_per_clause', 'mmse', 'mid_pause']\n",
      "F1-Macro: 0.6349 ± 0.1542\n",
      "Precision-Macro: 0.6360\n",
      "Recall-Macro: 0.6825\n",
      "F1-Macro: 0.6218 ± 0.1890\n",
      "Precision-Macro: 0.6314\n",
      "Recall-Macro: 0.6372\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['on', 'co', 'mean_sent_embs', 'verbs_with_inflections', 'nouns_with_determiners', 'pid', 'pid_efficiency', 'mmse']\n",
      "F1-Macro: 0.9649 ± 0.0287\n",
      "Precision-Macro: 0.9635\n",
      "Recall-Macro: 0.9698\n",
      "F1-Macro: 0.9257 ± 0.0444\n",
      "Precision-Macro: 0.9297\n",
      "Recall-Macro: 0.9282\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['on', 'mmse']\n",
      "F1-Macro: 0.9525 ± 0.0273\n",
      "Precision-Macro: 0.9520\n",
      "Recall-Macro: 0.9579\n",
      "F1-Macro: 0.9622 ± 0.0315\n",
      "Precision-Macro: 0.9610\n",
      "Recall-Macro: 0.9682\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['mlu', 'mmse']\n",
      "F1-Macro: 0.9575 ± 0.0327\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9640\n",
      "F1-Macro: 0.9551 ± 0.0339\n",
      "Precision-Macro: 0.9540\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['co', 'mmse', 'short_pause', 'mean_surprisal']\n",
      "F1-Macro: 0.7103 ± 0.0832\n",
      "Precision-Macro: 0.7223\n",
      "Recall-Macro: 0.7165\n",
      "F1-Macro: 0.5972 ± 0.0315\n",
      "Precision-Macro: 0.5778\n",
      "Recall-Macro: 0.6240\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['on', 'mean_sent_embs', 'tree_depth', 'sid_efficiency', 'mmse', 'mid_pause', 'mean_surprisal']\n",
      "F1-Macro: 0.6527 ± 0.0830\n",
      "Precision-Macro: 0.6825\n",
      "Recall-Macro: 0.6768\n",
      "F1-Macro: 0.6640 ± 0.0767\n",
      "Precision-Macro: 0.6686\n",
      "Recall-Macro: 0.6736\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['co', 'stop_words', 'tree_depth', 'pid_efficiency', 'mmse']\n",
      "F1-Macro: 0.7220 ± 0.0472\n",
      "Precision-Macro: 0.7297\n",
      "Recall-Macro: 0.7835\n",
      "F1-Macro: 0.6872 ± 0.0876\n",
      "Precision-Macro: 0.7010\n",
      "Recall-Macro: 0.6910\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    all_numeric = task_df.select_dtypes(include=[np.number]).drop(columns=['speaking time (s)']).columns.tolist()\n",
    "\n",
    "    X_num_all = task_df[all_numeric].values\n",
    "    numeric_feature_names = all_numeric\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        sfs = SFS(\n",
    "            estimator=clone(model),\n",
    "            k_features='best',\n",
    "            floating=True,\n",
    "            scoring=f1_macro_scorer,\n",
    "            cv=kf,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        sfs = sfs.fit(X_num_all, y)\n",
    "        selected_idx = list(sfs.k_feature_idx_)\n",
    "        selected_features = [numeric_feature_names[i] for i in selected_idx]\n",
    "        X_selected = task_df[selected_features]\n",
    "        print(\"Selected numeric features: \", selected_features)\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), selected_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X_selected, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"+\".join(selected_features),\n",
    "        })\n",
    "\n",
    "        ### TF-IDF + Selected Features\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "                ('mmse', StandardScaler(), ['mmse'])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        X_selected = task_df[['speech'] + selected_features]\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X_selected, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"+\".join([\"TF-IDF\"] + selected_features)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0c861",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e5ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e67abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame(results)\n",
    "# all_results.to_csv(\"all_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad6093b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.571365</td>\n",
       "      <td>0.606726</td>\n",
       "      <td>0.613954</td>\n",
       "      <td>0.112546</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.616925</td>\n",
       "      <td>0.665836</td>\n",
       "      <td>0.640670</td>\n",
       "      <td>0.150424</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Task                Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "0       MCI vs. AD        Random Forest       0.820021              0.778155   \n",
       "1       MCI vs. AD                  SVM       0.820021              0.778155   \n",
       "2       MCI vs. AD  Logistic Regression       0.820021              0.778155   \n",
       "3  MCI vs. Control        Random Forest       0.571365              0.606726   \n",
       "4  MCI vs. Control                  SVM       0.616925              0.665836   \n",
       "\n",
       "   Mean Recall Macro    Std F1  Type  \n",
       "0           0.931896  0.074311  MMSE  \n",
       "1           0.931896  0.074311  MMSE  \n",
       "2           0.931896  0.074311  MMSE  \n",
       "3           0.613954  0.112546  MMSE  \n",
       "4           0.640670  0.150424  MMSE  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe8489be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[all_results[\"Model\"] == \"SVM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9492fabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.962242</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.968169</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.849255</td>\n",
       "      <td>0.821257</td>\n",
       "      <td>0.922562</td>\n",
       "      <td>0.081628</td>\n",
       "      <td>TF-IDF+mmse+stop_words+verbs_with_inflections+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.754181</td>\n",
       "      <td>0.759700</td>\n",
       "      <td>0.772782</td>\n",
       "      <td>0.083009</td>\n",
       "      <td>TF-IDF+mmse+co+mean_surprisal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.704522</td>\n",
       "      <td>0.744655</td>\n",
       "      <td>0.688144</td>\n",
       "      <td>0.184661</td>\n",
       "      <td>TF-IDF+mmse+mean_surprisal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Task Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "31          AD vs. Control   SVM       0.962242              0.961029   \n",
       "61              MCI vs. AD   SVM       0.849255              0.821257   \n",
       "70  MCI vs. AD vs. Control   SVM       0.754181              0.759700   \n",
       "64         MCI vs. Control   SVM       0.704522              0.744655   \n",
       "\n",
       "    Mean Recall Macro    Std F1  \\\n",
       "31           0.968169  0.031528   \n",
       "61           0.922562  0.081628   \n",
       "70           0.772782  0.083009   \n",
       "64           0.688144  0.184661   \n",
       "\n",
       "                                                 Type  \n",
       "31                                      TF-IDF + MMSE  \n",
       "61  TF-IDF+mmse+stop_words+verbs_with_inflections+...  \n",
       "70                      TF-IDF+mmse+co+mean_surprisal  \n",
       "64                         TF-IDF+mmse+mean_surprisal  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.loc[all_results.groupby(\"Task\")[\"Mean F1 Macro\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224cda2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
