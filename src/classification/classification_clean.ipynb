{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bf877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7705db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e64ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/kirillkonca/Documents/dementia_prediction/data_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becc6cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>speech</th>\n",
       "      <th>annotation</th>\n",
       "      <th>speaking time (s)</th>\n",
       "      <th>on</th>\n",
       "      <th>co</th>\n",
       "      <th>mean_sent_embs</th>\n",
       "      <th>mlu</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>...</th>\n",
       "      <th>sid_efficiency</th>\n",
       "      <th>pid</th>\n",
       "      <th>pid_efficiency</th>\n",
       "      <th>maas</th>\n",
       "      <th>frazier_score</th>\n",
       "      <th>words_per_clause</th>\n",
       "      <th>mmse</th>\n",
       "      <th>short_pause</th>\n",
       "      <th>mid_pause</th>\n",
       "      <th>long_pause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138-1</td>\n",
       "      <td>Control</td>\n",
       "      <td>there's a cookie jar on the shelf . and the li...</td>\n",
       "      <td># sent_id = 1\\n# text = there's a cookie jar o...</td>\n",
       "      <td>46.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.802693</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>0.589552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.123539</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.025319</td>\n",
       "      <td>0.727537</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631-0</td>\n",
       "      <td>Control</td>\n",
       "      <td>the kids are in the cookies . the stool is fal...</td>\n",
       "      <td># sent_id = 1\\n# text = the kids are in the co...</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.853938</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.107872</td>\n",
       "      <td>0.059091</td>\n",
       "      <td>0.233236</td>\n",
       "      <td>0.024072</td>\n",
       "      <td>0.868304</td>\n",
       "      <td>4.461538</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121-0</td>\n",
       "      <td>Control</td>\n",
       "      <td>the boy is taking a cookie out of the cookie j...</td>\n",
       "      <td># sent_id = 1\\n# text = the boy is taking a co...</td>\n",
       "      <td>128.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.801815</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788754</td>\n",
       "      <td>0.218210</td>\n",
       "      <td>0.554471</td>\n",
       "      <td>0.026686</td>\n",
       "      <td>0.719372</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142-3</td>\n",
       "      <td>Control</td>\n",
       "      <td>the water's running over on the floor . the st...</td>\n",
       "      <td># sent_id = 1\\n# text = the water's running ov...</td>\n",
       "      <td>16.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.838216</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070155</td>\n",
       "      <td>0.280952</td>\n",
       "      <td>0.653983</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>1.004314</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267-2</td>\n",
       "      <td>Control</td>\n",
       "      <td>mother is drying the dishes and looking out th...</td>\n",
       "      <td># sent_id = 1\\n# text = mother is drying the d...</td>\n",
       "      <td>39.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795138</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>...</td>\n",
       "      <td>1.133216</td>\n",
       "      <td>0.304233</td>\n",
       "      <td>0.956938</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.910656</td>\n",
       "      <td>6.529412</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id diagnosis                                             speech  \\\n",
       "0  138-1   Control  there's a cookie jar on the shelf . and the li...   \n",
       "1  631-0   Control  the kids are in the cookies . the stool is fal...   \n",
       "2  121-0   Control  the boy is taking a cookie out of the cookie j...   \n",
       "3  142-3   Control  the water's running over on the floor . the st...   \n",
       "4  267-2   Control  mother is drying the dishes and looking out th...   \n",
       "\n",
       "                                          annotation  speaking time (s)   on  \\\n",
       "0  # sent_id = 1\\n# text = there's a cookie jar o...              46.20  0.0   \n",
       "1  # sent_id = 1\\n# text = the kids are in the co...              17.15  0.0   \n",
       "2  # sent_id = 1\\n# text = the boy is taking a co...             128.05  0.0   \n",
       "3  # sent_id = 1\\n# text = the water's running ov...              16.82  0.0   \n",
       "4  # sent_id = 1\\n# text = mother is drying the d...              39.71  0.0   \n",
       "\n",
       "         co  mean_sent_embs        mlu  stop_words  ...  sid_efficiency  \\\n",
       "0  0.105263        0.802693   9.571429    0.589552  ...        0.974026   \n",
       "1  0.000000        0.853938   7.250000    0.534483  ...        1.107872   \n",
       "2  0.153846        0.801815  11.666667    0.567857  ...        0.788754   \n",
       "3  0.285714        0.838216   7.000000    0.500000  ...        1.070155   \n",
       "4  0.000000        0.795138  10.090909    0.549550  ...        1.133216   \n",
       "\n",
       "        pid  pid_efficiency      maas  frazier_score  words_per_clause  mmse  \\\n",
       "0  0.123539        0.324675  0.025319       0.727537          6.090909  28.0   \n",
       "1  0.059091        0.233236  0.024072       0.868304          4.461538  29.0   \n",
       "2  0.218210        0.554471  0.026686       0.719372          6.666667  30.0   \n",
       "3  0.280952        0.653983  0.019465       1.004314          6.000000  30.0   \n",
       "4  0.304233        0.956938  0.023439       0.910656          6.529412  30.0   \n",
       "\n",
       "   short_pause  mid_pause  long_pause  \n",
       "0            0          0           1  \n",
       "1            0          0           0  \n",
       "2            0          1           0  \n",
       "3            0          0           0  \n",
       "4            2          0           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c2c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average=\"macro\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = list(stop_words)\n",
    "scoring = {\n",
    "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'recall_macro': make_scorer(recall_score, average='macro', zero_division=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6648bd",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a2b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ca56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MCI vs. AD\": df[df['diagnosis'].isin(['MCI', 'AD'])],\n",
    "    \"MCI vs. Control\": df[df['diagnosis'].isin(['MCI', 'Control'])],\n",
    "    \"AD vs. Control\": df[df['diagnosis'].isin(['AD', 'Control'])],\n",
    "    \"MCI vs. AD vs. Control\": df\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"SVM\": SVC(random_state=42, class_weight='balanced'),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d953b9",
   "metadata": {},
   "source": [
    "## MMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4d65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.8200 Â± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8200 Â± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8200 Â± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5714 Â± 0.1125\n",
      "Precision-Macro: 0.6067\n",
      "Recall-Macro: 0.6140\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6169 Â± 0.1504\n",
      "Precision-Macro: 0.6658\n",
      "Recall-Macro: 0.6407\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6109 Â± 0.1687\n",
      "Precision-Macro: 0.6256\n",
      "Recall-Macro: 0.6503\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9575 Â± 0.0327\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9640\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9550 Â± 0.0321\n",
      "Precision-Macro: 0.9552\n",
      "Recall-Macro: 0.9603\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9571 Â± 0.0401\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.6755 Â± 0.0696\n",
      "Precision-Macro: 0.7061\n",
      "Recall-Macro: 0.7279\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6951 Â± 0.0567\n",
      "Precision-Macro: 0.7134\n",
      "Recall-Macro: 0.7616\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6951 Â± 0.0567\n",
      "Precision-Macro: 0.7134\n",
      "Recall-Macro: 0.7616\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df[['mmse']].values\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        cv_results = cross_validate(model, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} Â± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"MMSE\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d0a23",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e91f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 Â± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.4679 Â± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6586 Â± 0.1372\n",
      "Precision-Macro: 0.6785\n",
      "Recall-Macro: 0.6610\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 Â± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5085 Â± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.4796 Â± 0.0915\n",
      "Precision-Macro: 0.4756\n",
      "Recall-Macro: 0.4958\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.8078 Â± 0.0699\n",
      "Precision-Macro: 0.8111\n",
      "Recall-Macro: 0.8112\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8082 Â± 0.0576\n",
      "Precision-Macro: 0.8120\n",
      "Recall-Macro: 0.8151\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.7814 Â± 0.0580\n",
      "Precision-Macro: 0.7875\n",
      "Recall-Macro: 0.7906\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5029 Â± 0.0276\n",
      "Precision-Macro: 0.4910\n",
      "Recall-Macro: 0.5239\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5140 Â± 0.0206\n",
      "Precision-Macro: 0.4968\n",
      "Recall-Macro: 0.5381\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5079 Â± 0.0340\n",
      "Precision-Macro: 0.5004\n",
      "Recall-Macro: 0.5217\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df['speech']\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words)),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} Â± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"TF-IDF + MMSE\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58a146",
   "metadata": {},
   "source": [
    "## TF-IDF + MMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2cdf1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 Â± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8170 Â± 0.0721\n",
      "Precision-Macro: 0.7851\n",
      "Recall-Macro: 0.8916\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8357 Â± 0.0816\n",
      "Precision-Macro: 0.7966\n",
      "Recall-Macro: 0.9386\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 Â± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6503 Â± 0.1624\n",
      "Precision-Macro: 0.7113\n",
      "Recall-Macro: 0.6416\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6218 Â± 0.1890\n",
      "Precision-Macro: 0.6314\n",
      "Recall-Macro: 0.6372\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9257 Â± 0.0444\n",
      "Precision-Macro: 0.9297\n",
      "Recall-Macro: 0.9282\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9622 Â± 0.0315\n",
      "Precision-Macro: 0.9610\n",
      "Recall-Macro: 0.9682\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9551 Â± 0.0339\n",
      "Precision-Macro: 0.9540\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5972 Â± 0.0315\n",
      "Precision-Macro: 0.5778\n",
      "Recall-Macro: 0.6240\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6640 Â± 0.0767\n",
      "Precision-Macro: 0.6686\n",
      "Recall-Macro: 0.6736\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6872 Â± 0.0876\n",
      "Precision-Macro: 0.7010\n",
      "Recall-Macro: 0.6910\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df[['speech', 'mmse']]\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    # Define column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "            ('mmse', StandardScaler(), ['mmse'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} Â± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"TF-IDF + MMSE\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ceaa035",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "129f4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.571365</td>\n",
       "      <td>0.606726</td>\n",
       "      <td>0.613954</td>\n",
       "      <td>0.112546</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.616925</td>\n",
       "      <td>0.665836</td>\n",
       "      <td>0.640670</td>\n",
       "      <td>0.150424</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Task                Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "0       MCI vs. AD        Random Forest       0.820021              0.778155   \n",
       "1       MCI vs. AD                  SVM       0.820021              0.778155   \n",
       "2       MCI vs. AD  Logistic Regression       0.820021              0.778155   \n",
       "3  MCI vs. Control        Random Forest       0.571365              0.606726   \n",
       "4  MCI vs. Control                  SVM       0.616925              0.665836   \n",
       "\n",
       "   Mean Recall Macro    Std F1  Type  \n",
       "0           0.931896  0.074311  MMSE  \n",
       "1           0.931896  0.074311  MMSE  \n",
       "2           0.931896  0.074311  MMSE  \n",
       "3           0.613954  0.112546  MMSE  \n",
       "4           0.640670  0.150424  MMSE  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97318c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.962242</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.968169</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.835719</td>\n",
       "      <td>0.796607</td>\n",
       "      <td>0.938616</td>\n",
       "      <td>0.081554</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.695081</td>\n",
       "      <td>0.713441</td>\n",
       "      <td>0.761550</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.650258</td>\n",
       "      <td>0.711317</td>\n",
       "      <td>0.641573</td>\n",
       "      <td>0.162386</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Task                Model  Mean F1 Macro  \\\n",
       "31          AD vs. Control                  SVM       0.962242   \n",
       "26              MCI vs. AD  Logistic Regression       0.835719   \n",
       "10  MCI vs. AD vs. Control                  SVM       0.695081   \n",
       "28         MCI vs. Control                  SVM       0.650258   \n",
       "\n",
       "    Mean Precision Macro  Mean Recall Macro    Std F1           Type  \n",
       "31              0.961029           0.968169  0.031528  TF-IDF + MMSE  \n",
       "26              0.796607           0.938616  0.081554  TF-IDF + MMSE  \n",
       "10              0.713441           0.761550  0.056706           MMSE  \n",
       "28              0.711317           0.641573  0.162386  TF-IDF + MMSE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_results.loc[baselines_results.groupby('Task')['Mean F1 Macro'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0025ffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['mean_sent_embs', 'nouns_with_determiners']\n",
      "Accuracy:  0.8441414141414141\n",
      "F1 Macro:  0.651820770959275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "# --- Setup ---\n",
    "text_column = 'speech'\n",
    "always_include_num = ['mmse']\n",
    "candidate_num = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "candidate_num.remove('mmse') # Replace with your actual feature names\n",
    "target = 'diagnosis'\n",
    "\n",
    "# --- Prepare your dataset ---\n",
    "# Ensure X is a DataFrame (important!)\n",
    "X = df[[text_column] + always_include_num + candidate_num].copy()\n",
    "y = df[target]\n",
    "\n",
    "# --- Step 1: Select features using SFS on numeric data only ---\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Use only candidate features for SFS\n",
    "X_sfs = df[candidate_num]\n",
    "\n",
    "sfs = SequentialFeatureSelector(\n",
    "    SVC(random_state=42, class_weight='balanced'),\n",
    "    n_features_to_select='auto',\n",
    "    direction='forward',\n",
    "    scoring='f1_macro',\n",
    "    tol = 0.005,\n",
    "    cv=kf,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "sfs.fit(X_sfs, y)\n",
    "\n",
    "selected_features = [name for name, selected in zip(candidate_num, sfs.get_support()) if selected]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# --- Step 2: Build final pipeline using selected features ---\n",
    "all_numeric = always_include_num + selected_features\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words), text_column),\n",
    "    ('num', StandardScaler(), all_numeric)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', SVC(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# --- Step 3: Cross-validation ---\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline, X, y,\n",
    "    cv=kf,\n",
    "    scoring=['accuracy', 'f1_macro'],\n",
    "    return_train_score=True,\n",
    "    error_score='raise'  # <- optional: force showing errors\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "print(\"Accuracy: \", np.mean(cv_results['test_accuracy']))\n",
    "print(\"F1 Macro: \", np.mean(cv_results['test_f1_macro']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee84c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Setup ---\n",
    "text_column = 'speech'\n",
    "always_include_num = ['mmse']\n",
    "candidate_num = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "candidate_num.remove('mmse')  # Remove mmse from candidate features, as it's in always_include_num\n",
    "target = 'diagnosis'\n",
    "\n",
    "# --- Prepare your dataset ---\n",
    "X = df[[text_column] + always_include_num + candidate_num].copy()\n",
    "y = df[target]\n",
    "\n",
    "# --- Step 1: Preprocess text and numeric features together ---\n",
    "# Define KFold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# ColumnTransformer to handle both TF-IDF and numeric columns together\n",
    "# We'll treat the entire TF-IDF as a single feature, so no need to break it down into words.\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words), text_column),  # For text column\n",
    "    ('num', StandardScaler(), always_include_num + candidate_num)  # For numeric features (including mmse)\n",
    "])\n",
    "\n",
    "# --- Step 2: Apply Sequential Feature Selection (SFS) to all features ---\n",
    "# SFS will be applied to the full combined feature set (TF-IDF as one feature, plus numeric ones)\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=SVC(random_state=42, class_weight='balanced'),\n",
    "    n_features_to_select='auto',  # Choose an optimal number of features\n",
    "    direction='forward',  # Forward selection (could also use 'backward')\n",
    "    scoring='f1_macro',\n",
    "    # tol=0.005,\n",
    "    cv=kf,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create the pipeline including preprocessing and feature selection\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('sfs', sfs),\n",
    "    ('clf', SVC(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# --- Step 3: Cross-validation ---\n",
    "cv_results = cross_validate(\n",
    "    pipeline, X, y,\n",
    "    cv=kf,\n",
    "    scoring=['accuracy', 'f1_macro'],\n",
    "    return_train_score=True,\n",
    "    error_score='raise'  # Optional: show errors\n",
    ")\n",
    "\n",
    "# Output results\n",
    "print(\"Accuracy: \", np.mean(cv_results['test_accuracy']))\n",
    "print(\"F1 Macro: \", np.mean(cv_results['test_f1_macro']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27737f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Setup ---\n",
    "text_column = 'speech'\n",
    "always_include_num = ['mmse']\n",
    "candidate_num = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "candidate_num.remove('mmse')  # Replace with your actual feature names\n",
    "target = 'diagnosis'\n",
    "\n",
    "# --- Prepare your dataset ---\n",
    "# Ensure X is a DataFrame (important!)\n",
    "X = df[[text_column] + always_include_num + candidate_num].copy()\n",
    "y = df[target]\n",
    "\n",
    "# --- Step 1: Select features using RFECV on numeric data only ---\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Use only candidate features for RFECV\n",
    "X_sfs = df[candidate_num]\n",
    "\n",
    "# Create a pipeline with a StandardScaler and SVC estimator\n",
    "estimator = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Feature scaling\n",
    "    ('svc', SVC(random_state=42, class_weight='balanced'))  # Model\n",
    "])\n",
    "\n",
    "# Set up the RFECV for feature selection\n",
    "rfecv = RFECV(\n",
    "    estimator=estimator,\n",
    "    step=1,  # Number of features to remove at each iteration\n",
    "    min_features_to_select=1,  # Minimum number of features to select\n",
    "    cv=kf,  # Cross-validation splitting strategy\n",
    "    scoring='f1_macro',  # Use f1_macro as the scoring metric\n",
    "    n_jobs=-1  # Parallelize across all CPUs\n",
    ")\n",
    "\n",
    "# Fit RFECV to the data\n",
    "rfecv.fit(X_sfs, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = [name for name, selected in zip(candidate_num, rfecv.support_) if selected]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# --- Step 2: Build final pipeline using selected features ---\n",
    "all_numeric = always_include_num + selected_features\n",
    "\n",
    "# Create the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words), text_column),\n",
    "    ('num', StandardScaler(), all_numeric)\n",
    "])\n",
    "\n",
    "# Build the final pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', SVC(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# --- Step 3: Cross-validation ---\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline, X, y,\n",
    "    cv=kf,\n",
    "    scoring=['accuracy', 'f1_macro'],\n",
    "    return_train_score=True,\n",
    "    error_score='raise'  # <- optional: force showing errors\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "print(\"Accuracy: \", np.mean(cv_results['test_accuracy']))\n",
    "print(\"F1 Macro: \", np.mean(cv_results['test_f1_macro']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412b2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Setup ---\n",
    "text_column = 'speech'\n",
    "always_include_num = ['mmse']\n",
    "candidate_num = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "candidate_num.remove('mmse')  # Replace with your actual feature names\n",
    "target = 'diagnosis'\n",
    "\n",
    "# --- Prepare your dataset ---\n",
    "# Ensure X is a DataFrame (important!)\n",
    "X = df[[text_column] + always_include_num + candidate_num].copy()\n",
    "y = df[target]\n",
    "\n",
    "# --- Step 1: Select features using RFECV on numeric data only ---\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Use only candidate features for RFECV\n",
    "X_sfs = df[candidate_num]\n",
    "\n",
    "# Set up the RFECV for feature selection\n",
    "rfecv = RFECV(\n",
    "    estimator=SVC(random_state=42, class_weight='balanced'),\n",
    "    step=1,  # Number of features to remove at each iteration\n",
    "    min_features_to_select=1,  # Minimum number of features to select\n",
    "    cv=kf,  # Cross-validation splitting strategy\n",
    "    scoring='f1_macro',  # Use f1_macro as the scoring metric\n",
    "    n_jobs=-1  # Parallelize across all CPUs\n",
    ")\n",
    "\n",
    "# Fit RFECV to the data\n",
    "rfecv.fit(X_sfs, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = [name for name, selected in zip(candidate_num, rfecv.support_) if selected]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# --- Step 2: Build final pipeline using selected features ---\n",
    "all_numeric = always_include_num + selected_features\n",
    "\n",
    "# Create the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words), text_column),\n",
    "    ('num', StandardScaler(), all_numeric)\n",
    "])\n",
    "\n",
    "# Build the final pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', SVC(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# --- Step 3: Cross-validation ---\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline, X, y,\n",
    "    cv=kf,\n",
    "    scoring=['accuracy', 'f1_macro'],\n",
    "    return_train_score=True,\n",
    "    error_score='raise'  # <- optional: force showing errors\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "print(\"Accuracy: \", np.mean(cv_results['test_accuracy']))\n",
    "print(\"F1 Macro: \", np.mean(cv_results['test_f1_macro']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f07fd46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features by RFECV: ['mmse', 'co', 'mean_sent_embs', 'tree_depth', 'nouns_with_determiners', 'sid_efficiency', 'pid_efficiency', 'frazier_score']\n",
      "Accuracy:  0.861868686868687\n",
      "F1 Macro:  0.6930257986614607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.feature_selection import RFECV\n",
    "import pandas as pd\n",
    "\n",
    "# --- Setup ---\n",
    "text_column = 'speech'\n",
    "always_include_num = ['mmse']\n",
    "candidate_num = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "candidate_num.remove('mmse')\n",
    "target = 'diagnosis'\n",
    "\n",
    "# --- Prepare your dataset ---\n",
    "# Ensure X is a DataFrame (important!)\n",
    "X = df[[text_column] + always_include_num + candidate_num].copy()\n",
    "y = df[target]\n",
    "\n",
    "# --- Step 1: Setup RFECV for feature selection ---\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Use all numeric features for RFECV selection\n",
    "X_rfecv = df[always_include_num + candidate_num]\n",
    "\n",
    "# Initialize the model for RFECV\n",
    "model = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Initialize RFECV with the model, step=1 removes one feature at a time, cv=5 is the number of cross-validation folds\n",
    "rfecv = RFECV(estimator=model, step=1, cv=KFold(10), scoring='f1_macro')\n",
    "X_rfecv_selected = rfecv.fit_transform(X_rfecv, y)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = [name for name, selected in zip(always_include_num + candidate_num, rfecv.support_) if selected]\n",
    "print(\"Selected features by RFECV:\", selected_features)\n",
    "\n",
    "# --- Step 2: Build final pipeline using selected features ---\n",
    "all_numeric = always_include_num + selected_features\n",
    "\n",
    "# Column transformer with TF-IDF for text and standard scaler for numeric features\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words), text_column),\n",
    "    ('num', StandardScaler(), all_numeric)\n",
    "])\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# --- Step 3: Cross-validation ---\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline, X, y,\n",
    "    cv=kf,\n",
    "    scoring=['accuracy', 'f1_macro'],\n",
    "    return_train_score=True,\n",
    "    error_score='raise'  # <- optional: force showing errors\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "print(\"Accuracy: \", np.mean(cv_results['test_accuracy']))\n",
    "print(\"F1 Macro: \", np.mean(cv_results['test_f1_macro']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb690891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
