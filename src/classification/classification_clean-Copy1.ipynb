{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bf877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7705db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e64ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/kirillkonca/Documents/dementia_prediction/data_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becc6cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>speech</th>\n",
       "      <th>annotation</th>\n",
       "      <th>speaking time (s)</th>\n",
       "      <th>on</th>\n",
       "      <th>co</th>\n",
       "      <th>mean_sent_embs</th>\n",
       "      <th>mlu</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>...</th>\n",
       "      <th>pid</th>\n",
       "      <th>pid_efficiency</th>\n",
       "      <th>maas</th>\n",
       "      <th>frazier_score</th>\n",
       "      <th>words_per_clause</th>\n",
       "      <th>mmse</th>\n",
       "      <th>short_pause</th>\n",
       "      <th>mid_pause</th>\n",
       "      <th>long_pause</th>\n",
       "      <th>mean_surprisal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138-1</td>\n",
       "      <td>Control</td>\n",
       "      <td>there's a cookie jar on the shelf . and the li...</td>\n",
       "      <td># sent_id = 1\\n# text = there's a cookie jar o...</td>\n",
       "      <td>46.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.802693</td>\n",
       "      <td>9.571429</td>\n",
       "      <td>0.589552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123539</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.025319</td>\n",
       "      <td>0.727537</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.843843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631-0</td>\n",
       "      <td>Control</td>\n",
       "      <td>the kids are in the cookies . the stool is fal...</td>\n",
       "      <td># sent_id = 1\\n# text = the kids are in the co...</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.853938</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059091</td>\n",
       "      <td>0.233236</td>\n",
       "      <td>0.024072</td>\n",
       "      <td>0.868304</td>\n",
       "      <td>4.461538</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.742492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121-0</td>\n",
       "      <td>Control</td>\n",
       "      <td>the boy is taking a cookie out of the cookie j...</td>\n",
       "      <td># sent_id = 1\\n# text = the boy is taking a co...</td>\n",
       "      <td>128.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.801815</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218210</td>\n",
       "      <td>0.554471</td>\n",
       "      <td>0.026686</td>\n",
       "      <td>0.719372</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.826125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142-3</td>\n",
       "      <td>Control</td>\n",
       "      <td>the water's running over on the floor . the st...</td>\n",
       "      <td># sent_id = 1\\n# text = the water's running ov...</td>\n",
       "      <td>16.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.838216</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280952</td>\n",
       "      <td>0.653983</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>1.004314</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.550135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267-2</td>\n",
       "      <td>Control</td>\n",
       "      <td>mother is drying the dishes and looking out th...</td>\n",
       "      <td># sent_id = 1\\n# text = mother is drying the d...</td>\n",
       "      <td>39.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795138</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304233</td>\n",
       "      <td>0.956938</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.910656</td>\n",
       "      <td>6.529412</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.018967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id diagnosis                                             speech  \\\n",
       "0  138-1   Control  there's a cookie jar on the shelf . and the li...   \n",
       "1  631-0   Control  the kids are in the cookies . the stool is fal...   \n",
       "2  121-0   Control  the boy is taking a cookie out of the cookie j...   \n",
       "3  142-3   Control  the water's running over on the floor . the st...   \n",
       "4  267-2   Control  mother is drying the dishes and looking out th...   \n",
       "\n",
       "                                          annotation  speaking time (s)   on  \\\n",
       "0  # sent_id = 1\\n# text = there's a cookie jar o...              46.20  0.0   \n",
       "1  # sent_id = 1\\n# text = the kids are in the co...              17.15  0.0   \n",
       "2  # sent_id = 1\\n# text = the boy is taking a co...             128.05  0.0   \n",
       "3  # sent_id = 1\\n# text = the water's running ov...              16.82  0.0   \n",
       "4  # sent_id = 1\\n# text = mother is drying the d...              39.71  0.0   \n",
       "\n",
       "         co  mean_sent_embs        mlu  stop_words  ...       pid  \\\n",
       "0  0.105263        0.802693   9.571429    0.589552  ...  0.123539   \n",
       "1  0.000000        0.853938   7.250000    0.534483  ...  0.059091   \n",
       "2  0.153846        0.801815  11.666667    0.567857  ...  0.218210   \n",
       "3  0.285714        0.838216   7.000000    0.500000  ...  0.280952   \n",
       "4  0.000000        0.795138  10.090909    0.549550  ...  0.304233   \n",
       "\n",
       "   pid_efficiency      maas  frazier_score  words_per_clause  mmse  \\\n",
       "0        0.324675  0.025319       0.727537          6.090909  28.0   \n",
       "1        0.233236  0.024072       0.868304          4.461538  29.0   \n",
       "2        0.554471  0.026686       0.719372          6.666667  30.0   \n",
       "3        0.653983  0.019465       1.004314          6.000000  30.0   \n",
       "4        0.956938  0.023439       0.910656          6.529412  30.0   \n",
       "\n",
       "   short_pause  mid_pause  long_pause  mean_surprisal  \n",
       "0            0          0           1        4.843843  \n",
       "1            0          0           0        5.742492  \n",
       "2            0          1           0        4.826125  \n",
       "3            0          0           0        6.550135  \n",
       "4            2          0           0        5.018967  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c2c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, average=\"macro\", zero_division=0)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = list(stop_words)\n",
    "scoring = {\n",
    "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "    'recall_macro': make_scorer(recall_score, average='macro', zero_division=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6648bd",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a2b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0ca56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"MCI vs. AD\": df[df['diagnosis'].isin(['MCI', 'AD'])],\n",
    "    \"MCI vs. Control\": df[df['diagnosis'].isin(['MCI', 'Control'])],\n",
    "    \"AD vs. Control\": df[df['diagnosis'].isin(['AD', 'Control'])],\n",
    "    \"MCI vs. AD vs. Control\": df\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"SVM\": SVC(random_state=42, class_weight='balanced'),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d953b9",
   "metadata": {},
   "source": [
    "## MMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4d65c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.8200 ¬± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8200 ¬± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8200 ¬± 0.0743\n",
      "Precision-Macro: 0.7782\n",
      "Recall-Macro: 0.9319\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5714 ¬± 0.1125\n",
      "Precision-Macro: 0.6067\n",
      "Recall-Macro: 0.6140\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6169 ¬± 0.1504\n",
      "Precision-Macro: 0.6658\n",
      "Recall-Macro: 0.6407\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6109 ¬± 0.1687\n",
      "Precision-Macro: 0.6256\n",
      "Recall-Macro: 0.6503\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9575 ¬± 0.0327\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9640\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9550 ¬± 0.0321\n",
      "Precision-Macro: 0.9552\n",
      "Recall-Macro: 0.9603\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9571 ¬± 0.0401\n",
      "Precision-Macro: 0.9562\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.6755 ¬± 0.0696\n",
      "Precision-Macro: 0.7061\n",
      "Recall-Macro: 0.7279\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6951 ¬± 0.0567\n",
      "Precision-Macro: 0.7134\n",
      "Recall-Macro: 0.7616\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6951 ¬± 0.0567\n",
      "Precision-Macro: 0.7134\n",
      "Recall-Macro: 0.7616\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df[['mmse']].values\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        cv_results = cross_validate(model, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ¬± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"MMSE\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d0a23",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e91f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 ¬± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.4679 ¬± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6586 ¬± 0.1372\n",
      "Precision-Macro: 0.6785\n",
      "Recall-Macro: 0.6610\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 ¬± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5085 ¬± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.4796 ¬± 0.0915\n",
      "Precision-Macro: 0.4756\n",
      "Recall-Macro: 0.4958\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.8078 ¬± 0.0699\n",
      "Precision-Macro: 0.8111\n",
      "Recall-Macro: 0.8112\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8082 ¬± 0.0576\n",
      "Precision-Macro: 0.8120\n",
      "Recall-Macro: 0.8151\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.7814 ¬± 0.0580\n",
      "Precision-Macro: 0.7875\n",
      "Recall-Macro: 0.7906\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5029 ¬± 0.0276\n",
      "Precision-Macro: 0.4910\n",
      "Recall-Macro: 0.5239\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5140 ¬± 0.0206\n",
      "Precision-Macro: 0.4968\n",
      "Recall-Macro: 0.5381\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5079 ¬± 0.0340\n",
      "Precision-Macro: 0.5004\n",
      "Recall-Macro: 0.5217\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df['speech']\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words)),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ¬± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"TF-IDF + MMSE\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58a146",
   "metadata": {},
   "source": [
    "## TF-IDF + MMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2cdf1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 ¬± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8170 ¬± 0.0721\n",
      "Precision-Macro: 0.7851\n",
      "Recall-Macro: 0.8916\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.8357 ¬± 0.0816\n",
      "Precision-Macro: 0.7966\n",
      "Recall-Macro: 0.9386\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 ¬± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6503 ¬± 0.1624\n",
      "Precision-Macro: 0.7113\n",
      "Recall-Macro: 0.6416\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6218 ¬± 0.1890\n",
      "Precision-Macro: 0.6314\n",
      "Recall-Macro: 0.6372\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.9257 ¬± 0.0444\n",
      "Precision-Macro: 0.9297\n",
      "Recall-Macro: 0.9282\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.9622 ¬± 0.0315\n",
      "Precision-Macro: 0.9610\n",
      "Recall-Macro: 0.9682\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.9551 ¬± 0.0339\n",
      "Precision-Macro: 0.9540\n",
      "Recall-Macro: 0.9613\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5972 ¬± 0.0315\n",
      "Precision-Macro: 0.5778\n",
      "Recall-Macro: 0.6240\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6640 ¬± 0.0767\n",
      "Precision-Macro: 0.6686\n",
      "Recall-Macro: 0.6736\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6872 ¬± 0.0876\n",
      "Precision-Macro: 0.7010\n",
      "Recall-Macro: 0.6910\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    X = task_df[['speech', 'mmse']]\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    # Define column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "            ('mmse', StandardScaler(), ['mmse'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ¬± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"TF-IDF + MMSE\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ceaa035",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "129f4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.571365</td>\n",
       "      <td>0.606726</td>\n",
       "      <td>0.613954</td>\n",
       "      <td>0.112546</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.616925</td>\n",
       "      <td>0.665836</td>\n",
       "      <td>0.640670</td>\n",
       "      <td>0.150424</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Task                Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "0       MCI vs. AD        Random Forest       0.820021              0.778155   \n",
       "1       MCI vs. AD                  SVM       0.820021              0.778155   \n",
       "2       MCI vs. AD  Logistic Regression       0.820021              0.778155   \n",
       "3  MCI vs. Control        Random Forest       0.571365              0.606726   \n",
       "4  MCI vs. Control                  SVM       0.616925              0.665836   \n",
       "\n",
       "   Mean Recall Macro    Std F1  Type  \n",
       "0           0.931896  0.074311  MMSE  \n",
       "1           0.931896  0.074311  MMSE  \n",
       "2           0.931896  0.074311  MMSE  \n",
       "3           0.613954  0.112546  MMSE  \n",
       "4           0.640670  0.150424  MMSE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97318c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.962242</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.968169</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.835719</td>\n",
       "      <td>0.796607</td>\n",
       "      <td>0.938616</td>\n",
       "      <td>0.081554</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.695081</td>\n",
       "      <td>0.713441</td>\n",
       "      <td>0.761550</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.650258</td>\n",
       "      <td>0.711317</td>\n",
       "      <td>0.641573</td>\n",
       "      <td>0.162386</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Task                Model  Mean F1 Macro  \\\n",
       "31          AD vs. Control                  SVM       0.962242   \n",
       "26              MCI vs. AD  Logistic Regression       0.835719   \n",
       "10  MCI vs. AD vs. Control                  SVM       0.695081   \n",
       "28         MCI vs. Control                  SVM       0.650258   \n",
       "\n",
       "    Mean Precision Macro  Mean Recall Macro    Std F1           Type  \n",
       "31              0.961029           0.968169  0.031528  TF-IDF + MMSE  \n",
       "26              0.796607           0.938616  0.081554  TF-IDF + MMSE  \n",
       "10              0.713441           0.761550  0.056706           MMSE  \n",
       "28              0.711317           0.641573  0.162386  TF-IDF + MMSE  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_results.loc[baselines_results.groupby('Task')['Mean F1 Macro'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ae63c",
   "metadata": {},
   "source": [
    "# All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de4dfbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4855 ¬± 0.0475\n",
      "Precision-Macro: 0.4916\n",
      "Recall-Macro: 0.5100\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.6089 ¬± 0.1301\n",
      "Precision-Macro: 0.6064\n",
      "Recall-Macro: 0.6609\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5714 ¬± 0.1224\n",
      "Precision-Macro: 0.5769\n",
      "Recall-Macro: 0.6327\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5072 ¬± 0.1652\n",
      "Precision-Macro: 0.4749\n",
      "Recall-Macro: 0.5475\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5535 ¬± 0.1232\n",
      "Precision-Macro: 0.5554\n",
      "Recall-Macro: 0.5913\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5651 ¬± 0.1167\n",
      "Precision-Macro: 0.5787\n",
      "Recall-Macro: 0.6356\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.7306 ¬± 0.0842\n",
      "Precision-Macro: 0.7439\n",
      "Recall-Macro: 0.7344\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.7665 ¬± 0.0683\n",
      "Precision-Macro: 0.7707\n",
      "Recall-Macro: 0.7756\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.7577 ¬± 0.0702\n",
      "Precision-Macro: 0.7605\n",
      "Recall-Macro: 0.7668\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4772 ¬± 0.0345\n",
      "Precision-Macro: 0.4649\n",
      "Recall-Macro: 0.4994\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5086 ¬± 0.0924\n",
      "Precision-Macro: 0.5254\n",
      "Recall-Macro: 0.5078\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5086 ¬± 0.0724\n",
      "Precision-Macro: 0.5359\n",
      "Recall-Macro: 0.5352\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    features_columns = task_df.select_dtypes(include=[np.number]).drop(columns=['speaking time (s)']).columns.tolist()\n",
    "    features_columns.remove('mmse')\n",
    "    X = task_df[features_columns]\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    # Define column transformer\n",
    "    #preprocessor = ColumnTransformer(\n",
    "    #    transformers=[\n",
    "    #        ('mmse', StandardScaler(), ['mmse'])\n",
    "    #    ]\n",
    "    #)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ¬± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"All Features\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3acbc",
   "metadata": {},
   "source": [
    "# TF-IDF + All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50821151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.4679 ¬± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.4679 ¬± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.6586 ¬± 0.1372\n",
      "Precision-Macro: 0.6785\n",
      "Recall-Macro: 0.6610\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5085 ¬± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5085 ¬± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.4796 ¬± 0.0915\n",
      "Precision-Macro: 0.4756\n",
      "Recall-Macro: 0.4958\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.8078 ¬± 0.0699\n",
      "Precision-Macro: 0.8111\n",
      "Recall-Macro: 0.8112\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.8082 ¬± 0.0576\n",
      "Precision-Macro: 0.8120\n",
      "Recall-Macro: 0.8151\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.7814 ¬± 0.0580\n",
      "Precision-Macro: 0.7875\n",
      "Recall-Macro: 0.7906\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "F1-Macro: 0.5029 ¬± 0.0276\n",
      "Precision-Macro: 0.4910\n",
      "Recall-Macro: 0.5239\n",
      "\n",
      "Model: SVM\n",
      "F1-Macro: 0.5140 ¬± 0.0206\n",
      "Precision-Macro: 0.4968\n",
      "Recall-Macro: 0.5381\n",
      "\n",
      "Model: Logistic Regression\n",
      "F1-Macro: 0.5079 ¬± 0.0340\n",
      "Precision-Macro: 0.5004\n",
      "Recall-Macro: 0.5217\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "    features_columns = task_df.select_dtypes(include=[np.number]).drop(columns=['speaking time (s)']).columns.tolist()\n",
    "    X = task_df[['speech'] + features_columns]\n",
    "    features_columns.remove('mmse')\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    # Define column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "            # ('mmse', StandardScaler(), ['mmse'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ¬± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"All Features\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c4097",
   "metadata": {},
   "source": [
    "# Linear Feature Addition to TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1657f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features.remove(\"speaking time (s)\")\n",
    "numerical_features.remove(\"mmse\")  # mmse will be added manually at the start\n",
    "# numerical_features.insert(0, \"mmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4670501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.4679\n",
      "\n",
      "Final Selected Features: [], Final F1-Macro: 0.4679\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.4679 ¬± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "‚úÖ Added Feature: on, New F1-Macro: 0.5415\n",
      "‚úÖ Added Feature: co, New F1-Macro: 0.5726\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.5751\n",
      "‚úÖ Added Feature: mlu, New F1-Macro: 0.6209\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.5971\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.6177\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5896\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.6230\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5841\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5777\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.6042\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.5694\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.6067\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.5830\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.5693\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.6004\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.6064\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.6127\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.6141\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mlu'], Final F1-Macro: 0.6209\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6209 ¬± 0.1142\n",
      "Precision-Macro: 0.6425\n",
      "Recall-Macro: 0.6400\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.6586\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.6539\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.6611\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.6135\n",
      "‚úÖ Added Feature: mlu, New F1-Macro: 0.6884\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.6564\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.6534\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.6732\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.6206\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.6520\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.6641\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.6806\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.6594\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.6477\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.6438\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.6751\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.6581\n",
      "‚úÖ Added Feature: mid_pause, New F1-Macro: 0.6971\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.6810\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.6730\n",
      "\n",
      "Final Selected Features: ['mlu', 'mid_pause'], Final F1-Macro: 0.6971\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6971 ¬± 0.1034\n",
      "Precision-Macro: 0.6986\n",
      "Recall-Macro: 0.7350\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.5085\n",
      "\n",
      "Final Selected Features: [], Final F1-Macro: 0.5085\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5085 ¬± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.4520\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.4947\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.4522\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.4517\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.4479\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.4483\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.4917\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.4508\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.4495\n",
      "‚úÖ Added Feature: sid_efficiency, New F1-Macro: 0.5276\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.5245\n",
      "‚úÖ Added Feature: pid_efficiency, New F1-Macro: 0.5701\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5394\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.5284\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.5354\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.5367\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.5516\n",
      "‚úÖ Added Feature: long_pause, New F1-Macro: 0.5770\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.5314\n",
      "\n",
      "Final Selected Features: ['sid_efficiency', 'pid_efficiency', 'long_pause'], Final F1-Macro: 0.5770\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5770 ¬± 0.0916\n",
      "Precision-Macro: 0.5945\n",
      "Recall-Macro: 0.6297\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4796\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.4796\n",
      "‚úÖ Added Feature: co, New F1-Macro: 0.4930\n",
      "‚úÖ Added Feature: mean_sent_embs, New F1-Macro: 0.5393\n",
      "‚úÖ Added Feature: mlu, New F1-Macro: 0.5514\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.4804\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.5197\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5097\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5420\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5221\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5492\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.5472\n",
      "‚úÖ Added Feature: pid_efficiency, New F1-Macro: 0.5883\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5671\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.5651\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.5793\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.5678\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.5898\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.5703\n",
      "‚úÖ Added Feature: mean_surprisal, New F1-Macro: 0.6160\n",
      "\n",
      "Final Selected Features: ['co', 'mean_sent_embs', 'mlu', 'pid_efficiency', 'mean_surprisal'], Final F1-Macro: 0.6160\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6160 ¬± 0.1261\n",
      "Precision-Macro: 0.6177\n",
      "Recall-Macro: 0.6579\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8078\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.7803\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.7685\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.7905\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.7816\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.7817\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.8025\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.7887\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.7696\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.7707\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.7859\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.7808\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.7990\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.7843\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.7652\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.7749\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.7867\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.7755\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.7824\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.7874\n",
      "\n",
      "Final Selected Features: [], Final F1-Macro: 0.8078\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8078 ¬± 0.0699\n",
      "Precision-Macro: 0.8111\n",
      "Recall-Macro: 0.8112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8082\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.7929\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.7680\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.7909\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.7993\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.7847\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.7855\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.7824\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.7711\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.7820\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.7964\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.7789\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.8055\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.7766\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.7666\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.7621\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.7904\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.7818\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.7852\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.7639\n",
      "\n",
      "Final Selected Features: [], Final F1-Macro: 0.8082\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8082 ¬± 0.0576\n",
      "Precision-Macro: 0.8120\n",
      "Recall-Macro: 0.8151\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.7814\n",
      "‚úÖ Added Feature: on, New F1-Macro: 0.7888\n",
      "‚úÖ Added Feature: co, New F1-Macro: 0.7931\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.7719\n",
      "‚úÖ Added Feature: mlu, New F1-Macro: 0.8014\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.8018\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.8022\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.7974\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.8014\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.8040\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.7893\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.8014\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.7871\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.7843\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.7946\n",
      "‚úÖ Added Feature: words_per_clause, New F1-Macro: 0.8061\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.8072\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.7944\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.7991\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.8070\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mlu', 'words_per_clause'], Final F1-Macro: 0.8061\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8061 ¬± 0.0746\n",
      "Precision-Macro: 0.8097\n",
      "Recall-Macro: 0.8133\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5029\n",
      "‚úÖ Added Feature: on, New F1-Macro: 0.5092\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.4873\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.4998\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.4744\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.4846\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.4878\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.4807\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.4813\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.4723\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.4882\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.4801\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.4908\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.4853\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.4817\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.4861\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.4882\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.4872\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.4917\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.4884\n",
      "\n",
      "Final Selected Features: ['on'], Final F1-Macro: 0.5092\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5092 ¬± 0.0295\n",
      "Precision-Macro: 0.4956\n",
      "Recall-Macro: 0.5309\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5140\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.5114\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.4751\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.4966\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.4981\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.4909\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.4911\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5076\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.4711\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.4918\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.4781\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.4903\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.4878\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5079\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.4836\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.4862\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.5075\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.4922\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.5013\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.4817\n",
      "\n",
      "Final Selected Features: [], Final F1-Macro: 0.5140\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5140 ¬± 0.0206\n",
      "Precision-Macro: 0.4968\n",
      "Recall-Macro: 0.5381\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5079\n",
      "‚úÖ Added Feature: on, New F1-Macro: 0.5140\n",
      "‚úÖ Added Feature: co, New F1-Macro: 0.5292\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.5180\n",
      "‚úÖ Added Feature: mlu, New F1-Macro: 0.5599\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.5336\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.5391\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5501\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5333\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5226\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5574\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.5476\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.5425\n",
      "‚úÖ Added Feature: maas, New F1-Macro: 0.5661\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.5610\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.5523\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.5554\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.5384\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.5511\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.5506\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mlu', 'maas'], Final F1-Macro: 0.5661\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5661 ¬± 0.1075\n",
      "Precision-Macro: 0.5971\n",
      "Recall-Macro: 0.5729\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        X_text = task_df[['speech']]  # Start with text only\n",
    "        y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "        # Define TF-IDF for baseline\n",
    "        tfidf = TfidfVectorizer(ngram_range=(1, 1), max_features=5000, stop_words=stop_words)\n",
    "\n",
    "        baseline_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech')\n",
    "        ])\n",
    "\n",
    "        baseline_pipeline = Pipeline([\n",
    "            ('preprocessor', baseline_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        # Baseline: TF-IDF only\n",
    "        baseline_score = cross_val_score(baseline_pipeline, X_text, y, cv=kf, scoring=f1_scorer).mean()\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Baseline (TF-IDF only) F1-Macro: {baseline_score:.4f}\")\n",
    "\n",
    "        # Feature selection loop\n",
    "        best_score = baseline_score\n",
    "        selected_features = []\n",
    "\n",
    "        for feature in numerical_features:\n",
    "\n",
    "            current_features = selected_features + [feature]\n",
    "\n",
    "            preprocessor = ColumnTransformer([\n",
    "                ('tfidf', tfidf, 'speech'),\n",
    "                ('num', StandardScaler(), current_features)\n",
    "            ])\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "\n",
    "            X_all = task_df[['speech'] + current_features]\n",
    "            new_score = cross_val_score(pipeline, X_all, y, cv=kf, scoring=f1_scorer).mean()\n",
    "\n",
    "            if new_score - best_score >= best_score * 0.005:\n",
    "                best_score = new_score\n",
    "                selected_features.append(feature)\n",
    "                print(f\"‚úÖ Added Feature: {feature}, New F1-Macro: {new_score:.4f}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Skipped Feature: {feature}, F1-Macro: {new_score:.4f}\")\n",
    "\n",
    "        print(f\"\\nFinal Selected Features: {selected_features}, Final F1-Macro: {best_score:.4f}\")\n",
    "\n",
    "        # Final evaluation with all selected features\n",
    "        final_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech'),\n",
    "            ('num', StandardScaler(), selected_features)\n",
    "        ]) if selected_features else ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech')\n",
    "        ])\n",
    "\n",
    "        final_pipeline = Pipeline([\n",
    "            ('preprocessor', final_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        X_final = task_df[['speech'] + selected_features] if selected_features else task_df[['speech']]\n",
    "\n",
    "        final_scores = cross_validate(final_pipeline, X_final, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"\\nüîé Final Evaluation with Selected Features:\")\n",
    "        print(f\"F1-Macro: {final_scores['test_f1_macro'].mean():.4f} ¬± {final_scores['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {final_scores['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {final_scores['test_recall_macro'].mean():.4f}\")\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": final_scores['test_f1_macro'].mean(),\n",
    "            \"Std F1\": final_scores['test_f1_macro'].std(),\n",
    "            \"Mean Precision Macro\": final_scores['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": final_scores['test_recall_macro'].mean(),\n",
    "            \"Type\": \"+\".join([\"TF-IDF\"] + selected_features) if selected_features else \"TF-IDF only\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e871a",
   "metadata": {},
   "source": [
    "# Linear Feature Deletion from TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd555d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.4679\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.4679\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.4679\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.4679 ¬± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4679\n",
      "‚úÖ Removed Feature: on, New F1-Macro: 0.6480\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.6381\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.5890\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.6033\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.5829\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.5598\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5701\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5637\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5552\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5685\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.5596\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.5477\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5496\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.6027\n",
      "‚úÖ Removed Feature: words_per_clause, New F1-Macro: 0.6628\n",
      "‚úÖ Removed Feature: short_pause, New F1-Macro: 0.6946\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.5380\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.5529\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.4679\n",
      "\n",
      "Final Selected Features: ['co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.6946\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6109 ¬± 0.1054\n",
      "Precision-Macro: 0.6098\n",
      "Recall-Macro: 0.6576\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.6586\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.6211\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.6246\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.6039\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.5888\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.5976\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.6058\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.6144\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5877\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5928\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5879\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.6083\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.6021\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5801\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.6085\n",
      "‚úÖ Removed Feature: words_per_clause, New F1-Macro: 0.6640\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.6262\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.6515\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.6479\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.6586\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.6640\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6095 ¬± 0.1036\n",
      "Precision-Macro: 0.6026\n",
      "Recall-Macro: 0.6742\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.5085\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5085\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5085 ¬± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5085\n",
      "‚úÖ Removed Feature: on, New F1-Macro: 0.5211\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.5046\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.4821\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.4980\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.4982\n",
      "‚úÖ Removed Feature: tree_depth, New F1-Macro: 0.5385\n",
      "‚úÖ Removed Feature: verbs_with_inflections, New F1-Macro: 0.5526\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5206\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5523\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5486\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.5386\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.5295\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5345\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.5085\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.5275\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.5541\n",
      "‚úÖ Removed Feature: mid_pause, New F1-Macro: 0.5767\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.4951\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.5085\n",
      "\n",
      "Final Selected Features: ['co', 'mean_sent_embs', 'mlu', 'stop_words', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5767\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.6159 ¬± 0.1350\n",
      "Precision-Macro: 0.6239\n",
      "Recall-Macro: 0.6459\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.4796\n",
      "‚úÖ Removed Feature: on, New F1-Macro: 0.5801\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.5708\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.5736\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.5802\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.5386\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.5544\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5631\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5613\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5625\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5487\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.5708\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.5462\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5232\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.5133\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.4847\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.4874\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.5066\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.5038\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.4796\n",
      "\n",
      "Final Selected Features: ['co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5801\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5801 ¬± 0.1126\n",
      "Precision-Macro: 0.5813\n",
      "Recall-Macro: 0.6310\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8078\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.7944\n",
      "‚úÖ Removed Feature: co, New F1-Macro: 0.8244\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.8194\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.8086\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.8021\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.7993\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.7913\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.8083\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.7899\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.7921\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.7739\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.7851\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.7775\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.7854\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.7990\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.7671\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.7950\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.7874\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.8078\n",
      "\n",
      "Final Selected Features: ['on', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.8244\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8175 ¬± 0.0841\n",
      "Precision-Macro: 0.8224\n",
      "Recall-Macro: 0.8195\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.8082\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.7647\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.7660\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.7439\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.7398\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.7489\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.7197\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.7324\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.7164\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.6687\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.6614\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.6758\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.6636\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.6459\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.6636\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.6930\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.7341\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.7517\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.7639\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.8082\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.8082\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.7724 ¬± 0.0761\n",
      "Precision-Macro: 0.7775\n",
      "Recall-Macro: 0.7846\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.7814\n",
      "‚úÖ Removed Feature: on, New F1-Macro: 0.7938\n",
      "‚úÖ Removed Feature: co, New F1-Macro: 0.7988\n",
      "‚úÖ Removed Feature: mean_sent_embs, New F1-Macro: 0.8033\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.7966\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.7936\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.7692\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.7706\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.7726\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.7599\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.7679\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.7705\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.7584\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.7913\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.8059\n",
      "‚úÖ Removed Feature: words_per_clause, New F1-Macro: 0.8090\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.7966\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.7900\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.7978\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.7814\n",
      "\n",
      "Final Selected Features: ['mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.8090\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.8140 ¬± 0.0655\n",
      "Precision-Macro: 0.8137\n",
      "Recall-Macro: 0.8230\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5029\n",
      "‚úÖ Removed Feature: on, New F1-Macro: 0.5120\n",
      "‚úÖ Removed Feature: co, New F1-Macro: 0.5229\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.4967\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.4980\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.5007\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.5064\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5077\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5090\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5082\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.4870\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.4863\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.4831\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.4953\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.4905\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.4822\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.4809\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.4857\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.5121\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.5029\n",
      "\n",
      "Final Selected Features: ['mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5229\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5229 ¬± 0.0509\n",
      "Precision-Macro: 0.5089\n",
      "Recall-Macro: 0.5445\n",
      "\n",
      "Model: SVM\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5140\n",
      "‚ùå Skipped Feature: on, F1-Macro: 0.4973\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.4983\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.4783\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.4944\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.4605\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.4539\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.4772\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.4476\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.4560\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.4480\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.4621\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.4613\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.4380\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.4184\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.4694\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.4759\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.4607\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.4817\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.5140\n",
      "\n",
      "Final Selected Features: ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5140\n",
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5255 ¬± 0.0806\n",
      "Precision-Macro: 0.5486\n",
      "Recall-Macro: 0.5249\n",
      "\n",
      "Model: Logistic Regression\n",
      "Baseline (TF-IDF only) F1-Macro: 0.5079\n",
      "‚úÖ Removed Feature: on, New F1-Macro: 0.5442\n",
      "‚ùå Skipped Feature: co, F1-Macro: 0.5396\n",
      "‚ùå Skipped Feature: mean_sent_embs, F1-Macro: 0.5228\n",
      "‚ùå Skipped Feature: mlu, F1-Macro: 0.5252\n",
      "‚ùå Skipped Feature: stop_words, F1-Macro: 0.5166\n",
      "‚ùå Skipped Feature: tree_depth, F1-Macro: 0.5356\n",
      "‚ùå Skipped Feature: verbs_with_inflections, F1-Macro: 0.5384\n",
      "‚ùå Skipped Feature: nouns_with_determiners, F1-Macro: 0.5174\n",
      "‚ùå Skipped Feature: sid, F1-Macro: 0.5190\n",
      "‚ùå Skipped Feature: sid_efficiency, F1-Macro: 0.5198\n",
      "‚ùå Skipped Feature: pid, F1-Macro: 0.5133\n",
      "‚ùå Skipped Feature: pid_efficiency, F1-Macro: 0.5274\n",
      "‚ùå Skipped Feature: maas, F1-Macro: 0.5326\n",
      "‚ùå Skipped Feature: frazier_score, F1-Macro: 0.5412\n",
      "‚ùå Skipped Feature: words_per_clause, F1-Macro: 0.5309\n",
      "‚ùå Skipped Feature: short_pause, F1-Macro: 0.5257\n",
      "‚ùå Skipped Feature: mid_pause, F1-Macro: 0.5221\n",
      "‚ùå Skipped Feature: long_pause, F1-Macro: 0.5245\n",
      "‚ùå Skipped Feature: mean_surprisal, F1-Macro: 0.5079\n",
      "\n",
      "Final Selected Features: ['co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'long_pause', 'mean_surprisal'], Final F1-Macro: 0.5442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Final Evaluation with Selected Features:\n",
      "F1-Macro: 0.5442 ¬± 0.0623\n",
      "Precision-Macro: 0.5494\n",
      "Recall-Macro: 0.5572\n"
     ]
    }
   ],
   "source": [
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        X_text = task_df[['speech']]  # Start with text only\n",
    "        y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "        baseline_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1, 1), max_features=5000, stop_words=stop_words), 'speech')\n",
    "        ])\n",
    "\n",
    "        baseline_pipeline = Pipeline([\n",
    "            ('preprocessor', baseline_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        # Baseline: TF-IDF only\n",
    "        baseline_score = cross_val_score(baseline_pipeline, X_text, y, cv=kf, scoring=f1_scorer).mean()\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Baseline (TF-IDF only) F1-Macro: {baseline_score:.4f}\")\n",
    "\n",
    "        # Feature selection loop\n",
    "        best_score = baseline_score\n",
    "        selected_features = numerical_features.copy()\n",
    "        current_features = selected_features.copy()\n",
    "        for feature in numerical_features:\n",
    "\n",
    "            current_features.remove(feature)\n",
    "\n",
    "            preprocessor = ColumnTransformer([\n",
    "                ('tfidf', tfidf, 'speech'),\n",
    "                ('num', StandardScaler(), current_features)\n",
    "            ])\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "\n",
    "            X_all = task_df[['speech'] + current_features]\n",
    "            new_score = cross_val_score(pipeline, X_all, y, cv=kf, scoring=f1_scorer).mean()\n",
    "\n",
    "            if new_score - best_score >= best_score * 0.005:\n",
    "                best_score = new_score\n",
    "                selected_features.remove(feature)\n",
    "                print(f\"‚úÖ Removed Feature: {feature}, New F1-Macro: {new_score:.4f}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Skipped Feature: {feature}, F1-Macro: {new_score:.4f}\")\n",
    "\n",
    "        print(f\"\\nFinal Selected Features: {selected_features}, Final F1-Macro: {best_score:.4f}\")\n",
    "\n",
    "        # Final evaluation with all selected features\n",
    "        final_preprocessor = ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech'),\n",
    "            ('num', StandardScaler(), selected_features)\n",
    "        ]) if selected_features else ColumnTransformer([\n",
    "            ('tfidf', tfidf, 'speech')\n",
    "        ])\n",
    "\n",
    "        final_pipeline = Pipeline([\n",
    "            ('preprocessor', final_preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        X_final = task_df[['speech'] + selected_features] if selected_features else task_df[['speech']]\n",
    "\n",
    "        final_scores = cross_validate(final_pipeline, X_final, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"\\nüîé Final Evaluation with Selected Features:\")\n",
    "        print(f\"F1-Macro: {final_scores['test_f1_macro'].mean():.4f} ¬± {final_scores['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {final_scores['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {final_scores['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": final_scores['test_f1_macro'].mean(),\n",
    "            \"Std F1\": final_scores['test_f1_macro'].std(),\n",
    "            \"Mean Precision Macro\": final_scores['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": final_scores['test_recall_macro'].mean(),\n",
    "            \"Type\": \"+\".join([\"TF-IDF\"] + selected_features) if selected_features else \"TF-IDF only\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86460f",
   "metadata": {},
   "source": [
    "# Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "515c0ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MCI vs. AD ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['tree_depth', 'sid_efficiency']\n",
      "F1-Macro: 0.6056 ¬± 0.0988\n",
      "Precision-Macro: 0.7129\n",
      "Recall-Macro: 0.5862\n",
      "F1-Macro: 0.4679 ¬± 0.0115\n",
      "Precision-Macro: 0.4400\n",
      "Recall-Macro: 0.5000\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['on', 'co', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'pid', 'pid_efficiency', 'frazier_score']\n",
      "F1-Macro: 0.5596 ¬± 0.1024\n",
      "Precision-Macro: 0.5671\n",
      "Recall-Macro: 0.5949\n",
      "F1-Macro: 0.5734 ¬± 0.1069\n",
      "Precision-Macro: 0.5787\n",
      "Recall-Macro: 0.5956\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['on', 'co', 'mean_sent_embs', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mid_pause', 'mean_surprisal']\n",
      "F1-Macro: 0.5557 ¬± 0.0619\n",
      "Precision-Macro: 0.5729\n",
      "Recall-Macro: 0.6461\n",
      "F1-Macro: 0.6008 ¬± 0.0815\n",
      "Precision-Macro: 0.5973\n",
      "Recall-Macro: 0.6559\n",
      "\n",
      "### MCI vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['words_per_clause', 'mid_pause', 'long_pause']\n",
      "F1-Macro: 0.5919 ¬± 0.1081\n",
      "Precision-Macro: 0.6079\n",
      "Recall-Macro: 0.5988\n",
      "F1-Macro: 0.5085 ¬± 0.1649\n",
      "Precision-Macro: 0.4751\n",
      "Recall-Macro: 0.5500\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['on', 'co', 'mean_sent_embs', 'stop_words', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency']\n",
      "F1-Macro: 0.5430 ¬± 0.0967\n",
      "Precision-Macro: 0.5658\n",
      "Recall-Macro: 0.5993\n",
      "F1-Macro: 0.5395 ¬± 0.1024\n",
      "Precision-Macro: 0.5534\n",
      "Recall-Macro: 0.5663\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['on', 'co', 'mean_sent_embs', 'stop_words', 'nouns_with_determiners', 'sid_efficiency', 'pid', 'maas', 'words_per_clause', 'mean_surprisal']\n",
      "F1-Macro: 0.5700 ¬± 0.1102\n",
      "Precision-Macro: 0.5852\n",
      "Recall-Macro: 0.6422\n",
      "F1-Macro: 0.6169 ¬± 0.1128\n",
      "Precision-Macro: 0.6299\n",
      "Recall-Macro: 0.6621\n",
      "\n",
      "### AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['on', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'maas', 'words_per_clause', 'mean_surprisal']\n",
      "F1-Macro: 0.7779 ¬± 0.0803\n",
      "Precision-Macro: 0.7874\n",
      "Recall-Macro: 0.7826\n",
      "F1-Macro: 0.8191 ¬± 0.0898\n",
      "Precision-Macro: 0.8227\n",
      "Recall-Macro: 0.8201\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['on', 'co', 'mean_sent_embs', 'stop_words', 'tree_depth', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score']\n",
      "F1-Macro: 0.7273 ¬± 0.0685\n",
      "Precision-Macro: 0.7326\n",
      "Recall-Macro: 0.7393\n",
      "F1-Macro: 0.7399 ¬± 0.0854\n",
      "Precision-Macro: 0.7485\n",
      "Recall-Macro: 0.7525\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['on', 'co', 'mean_sent_embs', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'nouns_with_determiners', 'sid', 'sid_efficiency', 'pid', 'maas', 'frazier_score', 'words_per_clause', 'short_pause', 'mean_surprisal']\n",
      "F1-Macro: 0.7600 ¬± 0.0526\n",
      "Precision-Macro: 0.7626\n",
      "Recall-Macro: 0.7691\n",
      "F1-Macro: 0.7946 ¬± 0.0800\n",
      "Precision-Macro: 0.7947\n",
      "Recall-Macro: 0.8028\n",
      "\n",
      "### MCI vs. AD vs. Control ###\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Selected numeric features:  ['on', 'mean_sent_embs', 'mlu', 'sid', 'sid_efficiency', 'pid', 'maas', 'mid_pause', 'mean_surprisal']\n",
      "F1-Macro: 0.4976 ¬± 0.0297\n",
      "Precision-Macro: 0.4838\n",
      "Recall-Macro: 0.5216\n",
      "F1-Macro: 0.5221 ¬± 0.0360\n",
      "Precision-Macro: 0.5084\n",
      "Recall-Macro: 0.5453\n",
      "\n",
      "Model: SVM\n",
      "Selected numeric features:  ['on', 'mean_sent_embs', 'stop_words', 'tree_depth', 'verbs_with_inflections', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'frazier_score', 'mid_pause', 'mean_surprisal']\n",
      "F1-Macro: 0.4924 ¬± 0.0782\n",
      "Precision-Macro: 0.5120\n",
      "Recall-Macro: 0.5011\n",
      "F1-Macro: 0.5004 ¬± 0.0662\n",
      "Precision-Macro: 0.5150\n",
      "Recall-Macro: 0.5094\n",
      "\n",
      "Model: Logistic Regression\n",
      "Selected numeric features:  ['on', 'mean_sent_embs', 'mlu', 'stop_words', 'tree_depth', 'sid', 'sid_efficiency', 'pid', 'pid_efficiency', 'maas', 'short_pause', 'mean_surprisal']\n",
      "F1-Macro: 0.5210 ¬± 0.0774\n",
      "Precision-Macro: 0.5424\n",
      "Recall-Macro: 0.5689\n",
      "F1-Macro: 0.5327 ¬± 0.0597\n",
      "Precision-Macro: 0.5365\n",
      "Recall-Macro: 0.5429\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "for task_name, task_df in tasks.items():\n",
    "    print(f\"\\n### {task_name} ###\\n\")\n",
    "\n",
    "    all_numeric = task_df.select_dtypes(include=[np.number]).drop(columns=['speaking time (s)', 'mmse']).columns.tolist()\n",
    "\n",
    "    X_num_all = task_df[all_numeric].values\n",
    "    numeric_feature_names = all_numeric\n",
    "    y = LabelEncoder().fit_transform(task_df['diagnosis'])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "        sfs = SFS(\n",
    "            estimator=clone(model),\n",
    "            k_features='best',\n",
    "            floating=True,\n",
    "            scoring=f1_macro_scorer,\n",
    "            cv=kf,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        sfs = sfs.fit(X_num_all, y)\n",
    "        selected_idx = list(sfs.k_feature_idx_)\n",
    "        selected_features = [numeric_feature_names[i] for i in selected_idx]\n",
    "        X_selected = task_df[selected_features]\n",
    "        print(\"Selected numeric features: \", selected_features)\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), selected_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X_selected, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ¬± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"+\".join(selected_features),\n",
    "        })\n",
    "\n",
    "        ### TF-IDF + Selected Features\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('tfidf', TfidfVectorizer(max_features=5000, stop_words=stop_words), 'speech'),\n",
    "                ('num', StandardScaler(), selected_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        X_selected = task_df[['speech'] + selected_features]\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X_selected, y, cv=kf, scoring=scoring)\n",
    "\n",
    "        print(f\"F1-Macro: {cv_results['test_f1_macro'].mean():.4f} ¬± {cv_results['test_f1_macro'].std():.4f}\")\n",
    "        print(f\"Precision-Macro: {cv_results['test_precision_macro'].mean():.4f}\")\n",
    "        print(f\"Recall-Macro: {cv_results['test_recall_macro'].mean():.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Task\": task_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Mean F1 Macro\": cv_results['test_f1_macro'].mean(),\n",
    "            \"Mean Precision Macro\": cv_results['test_precision_macro'].mean(),\n",
    "            \"Mean Recall Macro\": cv_results['test_recall_macro'].mean(),\n",
    "            \"Std F1\": cv_results['test_f1_macro'].std(),\n",
    "            \"Type\": \"+\".join([\"TF-IDF\"] + selected_features)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0c861",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e5ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a1f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.read_csv(\"/Users/kirillkonca/Documents/dementia_prediction/src/classification/all_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e67abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_results = pd.DataFrame(results)\n",
    "# all_results.to_csv(\"all_results_no_mmse.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad6093b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.485457</td>\n",
       "      <td>0.491595</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.047501</td>\n",
       "      <td>All Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.608908</td>\n",
       "      <td>0.606402</td>\n",
       "      <td>0.660881</td>\n",
       "      <td>0.130124</td>\n",
       "      <td>All Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.571391</td>\n",
       "      <td>0.576852</td>\n",
       "      <td>0.632701</td>\n",
       "      <td>0.122443</td>\n",
       "      <td>All Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.507241</td>\n",
       "      <td>0.474892</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.165193</td>\n",
       "      <td>All Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.553519</td>\n",
       "      <td>0.555417</td>\n",
       "      <td>0.591310</td>\n",
       "      <td>0.123193</td>\n",
       "      <td>All Features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Task                Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "0       MCI vs. AD        Random Forest       0.485457              0.491595   \n",
       "1       MCI vs. AD                  SVM       0.608908              0.606402   \n",
       "2       MCI vs. AD  Logistic Regression       0.571391              0.576852   \n",
       "3  MCI vs. Control        Random Forest       0.507241              0.474892   \n",
       "4  MCI vs. Control                  SVM       0.553519              0.555417   \n",
       "\n",
       "   Mean Recall Macro    Std F1          Type  \n",
       "0           0.510000  0.047501  All Features  \n",
       "1           0.660881  0.130124  All Features  \n",
       "2           0.632701  0.122443  All Features  \n",
       "3           0.547500  0.165193  All Features  \n",
       "4           0.591310  0.123193  All Features  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe8489be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[(all_results[\"Model\"] == \"SVM\") & (all_results[\"Type\"] != \"TF-IDF + MMSE\") & (all_results[\"Type\"] != \"TF-IDF+mmse\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9492fabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.962242</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.968169</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>All Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.855281</td>\n",
       "      <td>0.823561</td>\n",
       "      <td>0.924456</td>\n",
       "      <td>0.087598</td>\n",
       "      <td>TF-IDF+mmse+stop_words+short_pause+mean_surprisal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.754181</td>\n",
       "      <td>0.759700</td>\n",
       "      <td>0.772782</td>\n",
       "      <td>0.083009</td>\n",
       "      <td>TF-IDF+mmse+co+mean_surprisal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.704522</td>\n",
       "      <td>0.744655</td>\n",
       "      <td>0.688144</td>\n",
       "      <td>0.184661</td>\n",
       "      <td>TF-IDF+mmse+mean_surprisal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Task Model  Mean F1 Macro  Mean Precision Macro  \\\n",
       "115          AD vs. Control   SVM       0.962242              0.961029   \n",
       "37               MCI vs. AD   SVM       0.855281              0.823561   \n",
       "46   MCI vs. AD vs. Control   SVM       0.754181              0.759700   \n",
       "40          MCI vs. Control   SVM       0.704522              0.744655   \n",
       "\n",
       "     Mean Recall Macro    Std F1  \\\n",
       "115           0.968169  0.031528   \n",
       "37            0.924456  0.087598   \n",
       "46            0.772782  0.083009   \n",
       "40            0.688144  0.184661   \n",
       "\n",
       "                                                  Type  \n",
       "115                                       All Features  \n",
       "37   TF-IDF+mmse+stop_words+short_pause+mean_surprisal  \n",
       "46                       TF-IDF+mmse+co+mean_surprisal  \n",
       "40                          TF-IDF+mmse+mean_surprisal  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.loc[all_results.groupby(\"Task\")[\"Mean F1 Macro\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bd14281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Task Model  Mean F1 Macro  Mean Precision Macro  \\\n",
      "19          AD vs. Control   SVM       0.808191              0.812006   \n",
      "25              MCI vs. AD   SVM       0.620941              0.642479   \n",
      "46  MCI vs. AD vs. Control   SVM       0.525539              0.548562   \n",
      "40         MCI vs. Control   SVM       0.615860              0.623888   \n",
      "\n",
      "    Mean Recall Macro    Std F1  \\\n",
      "19           0.815132  0.057582   \n",
      "25           0.640024  0.114222   \n",
      "46           0.524889  0.080611   \n",
      "40           0.645919  0.134966   \n",
      "\n",
      "                                                                                                                                                                                                                             Type  \n",
      "19                                                                                                                                                                                                                   All Features  \n",
      "25                                                                                                                                                                                                               TF-IDF+on+co+mlu  \n",
      "46  TF-IDF+on+co+mean_sent_embs+mlu+stop_words+tree_depth+verbs_with_inflections+nouns_with_determiners+sid+sid_efficiency+pid+pid_efficiency+maas+frazier_score+words_per_clause+short_pause+mid_pause+long_pause+mean_surprisal  \n",
      "40                                                 TF-IDF+co+mean_sent_embs+mlu+stop_words+nouns_with_determiners+sid+sid_efficiency+pid+pid_efficiency+maas+frazier_score+words_per_clause+short_pause+long_pause+mean_surprisal  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set options to fully display the table\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Your statement\n",
    "print(all_results.loc[all_results.groupby(\"Task\")[\"Mean F1 Macro\"].idxmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84ba6bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.965005</td>\n",
       "      <td>0.963802</td>\n",
       "      <td>0.968849</td>\n",
       "      <td>0.028029</td>\n",
       "      <td>on+co+nouns_with_determiners+pid_efficiency+fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.855281</td>\n",
       "      <td>0.823561</td>\n",
       "      <td>0.924456</td>\n",
       "      <td>0.087598</td>\n",
       "      <td>TF-IDF+mmse+stop_words+short_pause+mean_surprisal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.754181</td>\n",
       "      <td>0.759700</td>\n",
       "      <td>0.772782</td>\n",
       "      <td>0.083009</td>\n",
       "      <td>TF-IDF+mmse+co+mean_surprisal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.704522</td>\n",
       "      <td>0.744655</td>\n",
       "      <td>0.688144</td>\n",
       "      <td>0.184661</td>\n",
       "      <td>TF-IDF+mmse+mean_surprisal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Task          Model  Mean F1 Macro  \\\n",
       "72          AD vs. Control  Random Forest       0.965005   \n",
       "37              MCI vs. AD            SVM       0.855281   \n",
       "46  MCI vs. AD vs. Control            SVM       0.754181   \n",
       "40         MCI vs. Control            SVM       0.704522   \n",
       "\n",
       "    Mean Precision Macro  Mean Recall Macro    Std F1  \\\n",
       "72              0.963802           0.968849  0.028029   \n",
       "37              0.823561           0.924456  0.087598   \n",
       "46              0.759700           0.772782  0.083009   \n",
       "40              0.744655           0.688144  0.184661   \n",
       "\n",
       "                                                 Type  \n",
       "72  on+co+nouns_with_determiners+pid_efficiency+fr...  \n",
       "37  TF-IDF+mmse+stop_words+short_pause+mean_surprisal  \n",
       "46                      TF-IDF+mmse+co+mean_surprisal  \n",
       "40                         TF-IDF+mmse+mean_surprisal  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.loc[all_results.groupby(\"Task\")[\"Mean F1 Macro\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[all_results[\"Type\"] == \"MMSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6672ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[~all_results[\"Type\"].str.contains(\"MMSE\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d0fa341",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[~all_results[\"Type\"].str.contains(\"mmse\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "713ba4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[~all_results[\"Type\"].str.contains(\"All Features\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c5b82df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Task                Model  Mean F1 Macro  \\\n",
      "104          AD vs. Control  Logistic Regression       0.813971   \n",
      "49               MCI vs. AD                  SVM       0.610913   \n",
      "59   MCI vs. AD vs. Control  Logistic Regression       0.544185   \n",
      "52          MCI vs. Control                  SVM       0.607346   \n",
      "\n",
      "     Mean Precision Macro  Mean Recall Macro    Std F1  \\\n",
      "104              0.813668           0.823049  0.065451   \n",
      "49               0.609846           0.657555  0.105388   \n",
      "59               0.549400           0.557156  0.062253   \n",
      "52               0.607686           0.642941  0.145048   \n",
      "\n",
      "                                                  Type  \n",
      "104  TF-IDF+mlu+stop_words+tree_depth+verbs_with_in...  \n",
      "49   TF-IDF+co+mean_sent_embs+mlu+stop_words+tree_d...  \n",
      "59   TF-IDF+co+mean_sent_embs+mlu+stop_words+tree_d...  \n",
      "52   TF-IDF+on+co+mean_sent_embs+mlu+stop_words+tre...  \n"
     ]
    }
   ],
   "source": [
    "print(all_results.loc[all_results.groupby(\"Task\")[\"Mean F1 Macro\"].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87935139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c1f7f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[\n",
    "    (all_results[\"Type\"].isin([\"TF-IDF only\", \"MMSE\", \"TF-IDF + MMSE\"]))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4e23d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean F1 Macro</th>\n",
       "      <th>Mean Precision Macro</th>\n",
       "      <th>Mean Recall Macro</th>\n",
       "      <th>Std F1</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.778155</td>\n",
       "      <td>0.931896</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.571365</td>\n",
       "      <td>0.606726</td>\n",
       "      <td>0.613954</td>\n",
       "      <td>0.112546</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.616925</td>\n",
       "      <td>0.665836</td>\n",
       "      <td>0.640670</td>\n",
       "      <td>0.150424</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.610909</td>\n",
       "      <td>0.625569</td>\n",
       "      <td>0.650304</td>\n",
       "      <td>0.168666</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.957511</td>\n",
       "      <td>0.956156</td>\n",
       "      <td>0.963973</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.955013</td>\n",
       "      <td>0.955205</td>\n",
       "      <td>0.960280</td>\n",
       "      <td>0.032073</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.957091</td>\n",
       "      <td>0.956218</td>\n",
       "      <td>0.961254</td>\n",
       "      <td>0.040132</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.675519</td>\n",
       "      <td>0.706114</td>\n",
       "      <td>0.727892</td>\n",
       "      <td>0.069574</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.695081</td>\n",
       "      <td>0.713441</td>\n",
       "      <td>0.761550</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.695081</td>\n",
       "      <td>0.713441</td>\n",
       "      <td>0.761550</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.467855</td>\n",
       "      <td>0.440028</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.467855</td>\n",
       "      <td>0.440028</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.658610</td>\n",
       "      <td>0.678456</td>\n",
       "      <td>0.661046</td>\n",
       "      <td>0.137172</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.508518</td>\n",
       "      <td>0.475108</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.164898</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.508518</td>\n",
       "      <td>0.475108</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.164898</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.479602</td>\n",
       "      <td>0.475572</td>\n",
       "      <td>0.495799</td>\n",
       "      <td>0.091490</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.807767</td>\n",
       "      <td>0.811095</td>\n",
       "      <td>0.811211</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.808191</td>\n",
       "      <td>0.812006</td>\n",
       "      <td>0.815132</td>\n",
       "      <td>0.057582</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.781427</td>\n",
       "      <td>0.787491</td>\n",
       "      <td>0.790581</td>\n",
       "      <td>0.058033</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.502949</td>\n",
       "      <td>0.491001</td>\n",
       "      <td>0.523883</td>\n",
       "      <td>0.027603</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.514034</td>\n",
       "      <td>0.496813</td>\n",
       "      <td>0.538101</td>\n",
       "      <td>0.020560</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.507925</td>\n",
       "      <td>0.500392</td>\n",
       "      <td>0.521684</td>\n",
       "      <td>0.033960</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.817012</td>\n",
       "      <td>0.785077</td>\n",
       "      <td>0.891623</td>\n",
       "      <td>0.072141</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.835719</td>\n",
       "      <td>0.796607</td>\n",
       "      <td>0.938616</td>\n",
       "      <td>0.081554</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.650258</td>\n",
       "      <td>0.711317</td>\n",
       "      <td>0.641573</td>\n",
       "      <td>0.162386</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.621796</td>\n",
       "      <td>0.631422</td>\n",
       "      <td>0.637203</td>\n",
       "      <td>0.189017</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.925718</td>\n",
       "      <td>0.929673</td>\n",
       "      <td>0.928231</td>\n",
       "      <td>0.044370</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.962242</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.968169</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AD vs. Control</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.955071</td>\n",
       "      <td>0.954017</td>\n",
       "      <td>0.961342</td>\n",
       "      <td>0.033873</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.597210</td>\n",
       "      <td>0.577759</td>\n",
       "      <td>0.624044</td>\n",
       "      <td>0.031462</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.664040</td>\n",
       "      <td>0.668554</td>\n",
       "      <td>0.673606</td>\n",
       "      <td>0.076650</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MCI vs. AD vs. Control</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.687190</td>\n",
       "      <td>0.700956</td>\n",
       "      <td>0.691003</td>\n",
       "      <td>0.087585</td>\n",
       "      <td>TF-IDF + MMSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MCI vs. AD</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.467855</td>\n",
       "      <td>0.440028</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>TF-IDF only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MCI vs. Control</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.508518</td>\n",
       "      <td>0.475108</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.164898</td>\n",
       "      <td>TF-IDF only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Task                Model  Mean F1 Macro  \\\n",
       "0               MCI vs. AD        Random Forest       0.820021   \n",
       "1               MCI vs. AD                  SVM       0.820021   \n",
       "2               MCI vs. AD  Logistic Regression       0.820021   \n",
       "3          MCI vs. Control        Random Forest       0.571365   \n",
       "4          MCI vs. Control                  SVM       0.616925   \n",
       "5          MCI vs. Control  Logistic Regression       0.610909   \n",
       "6           AD vs. Control        Random Forest       0.957511   \n",
       "7           AD vs. Control                  SVM       0.955013   \n",
       "8           AD vs. Control  Logistic Regression       0.957091   \n",
       "9   MCI vs. AD vs. Control        Random Forest       0.675519   \n",
       "10  MCI vs. AD vs. Control                  SVM       0.695081   \n",
       "11  MCI vs. AD vs. Control  Logistic Regression       0.695081   \n",
       "12              MCI vs. AD        Random Forest       0.467855   \n",
       "13              MCI vs. AD                  SVM       0.467855   \n",
       "14              MCI vs. AD  Logistic Regression       0.658610   \n",
       "15         MCI vs. Control        Random Forest       0.508518   \n",
       "16         MCI vs. Control                  SVM       0.508518   \n",
       "17         MCI vs. Control  Logistic Regression       0.479602   \n",
       "18          AD vs. Control        Random Forest       0.807767   \n",
       "19          AD vs. Control                  SVM       0.808191   \n",
       "20          AD vs. Control  Logistic Regression       0.781427   \n",
       "21  MCI vs. AD vs. Control        Random Forest       0.502949   \n",
       "22  MCI vs. AD vs. Control                  SVM       0.514034   \n",
       "23  MCI vs. AD vs. Control  Logistic Regression       0.507925   \n",
       "25              MCI vs. AD                  SVM       0.817012   \n",
       "26              MCI vs. AD  Logistic Regression       0.835719   \n",
       "28         MCI vs. Control                  SVM       0.650258   \n",
       "29         MCI vs. Control  Logistic Regression       0.621796   \n",
       "30          AD vs. Control        Random Forest       0.925718   \n",
       "31          AD vs. Control                  SVM       0.962242   \n",
       "32          AD vs. Control  Logistic Regression       0.955071   \n",
       "33  MCI vs. AD vs. Control        Random Forest       0.597210   \n",
       "34  MCI vs. AD vs. Control                  SVM       0.664040   \n",
       "35  MCI vs. AD vs. Control  Logistic Regression       0.687190   \n",
       "36              MCI vs. AD        Random Forest       0.467855   \n",
       "39         MCI vs. Control        Random Forest       0.508518   \n",
       "\n",
       "    Mean Precision Macro  Mean Recall Macro    Std F1           Type  \n",
       "0               0.778155           0.931896  0.074311           MMSE  \n",
       "1               0.778155           0.931896  0.074311           MMSE  \n",
       "2               0.778155           0.931896  0.074311           MMSE  \n",
       "3               0.606726           0.613954  0.112546           MMSE  \n",
       "4               0.665836           0.640670  0.150424           MMSE  \n",
       "5               0.625569           0.650304  0.168666           MMSE  \n",
       "6               0.956156           0.963973  0.032660           MMSE  \n",
       "7               0.955205           0.960280  0.032073           MMSE  \n",
       "8               0.956218           0.961254  0.040132           MMSE  \n",
       "9               0.706114           0.727892  0.069574           MMSE  \n",
       "10              0.713441           0.761550  0.056706           MMSE  \n",
       "11              0.713441           0.761550  0.056706           MMSE  \n",
       "12              0.440028           0.500000  0.011503  TF-IDF + MMSE  \n",
       "13              0.440028           0.500000  0.011503  TF-IDF + MMSE  \n",
       "14              0.678456           0.661046  0.137172  TF-IDF + MMSE  \n",
       "15              0.475108           0.550000  0.164898  TF-IDF + MMSE  \n",
       "16              0.475108           0.550000  0.164898  TF-IDF + MMSE  \n",
       "17              0.475572           0.495799  0.091490  TF-IDF + MMSE  \n",
       "18              0.811095           0.811211  0.069873  TF-IDF + MMSE  \n",
       "19              0.812006           0.815132  0.057582  TF-IDF + MMSE  \n",
       "20              0.787491           0.790581  0.058033  TF-IDF + MMSE  \n",
       "21              0.491001           0.523883  0.027603  TF-IDF + MMSE  \n",
       "22              0.496813           0.538101  0.020560  TF-IDF + MMSE  \n",
       "23              0.500392           0.521684  0.033960  TF-IDF + MMSE  \n",
       "25              0.785077           0.891623  0.072141  TF-IDF + MMSE  \n",
       "26              0.796607           0.938616  0.081554  TF-IDF + MMSE  \n",
       "28              0.711317           0.641573  0.162386  TF-IDF + MMSE  \n",
       "29              0.631422           0.637203  0.189017  TF-IDF + MMSE  \n",
       "30              0.929673           0.928231  0.044370  TF-IDF + MMSE  \n",
       "31              0.961029           0.968169  0.031528  TF-IDF + MMSE  \n",
       "32              0.954017           0.961342  0.033873  TF-IDF + MMSE  \n",
       "33              0.577759           0.624044  0.031462  TF-IDF + MMSE  \n",
       "34              0.668554           0.673606  0.076650  TF-IDF + MMSE  \n",
       "35              0.700956           0.691003  0.087585  TF-IDF + MMSE  \n",
       "36              0.440028           0.500000  0.011503    TF-IDF only  \n",
       "39              0.475108           0.550000  0.164898    TF-IDF only  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324b8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
